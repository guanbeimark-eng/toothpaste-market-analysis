# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import re
import numpy as np

# =============================================================================
# 1. åŸºç¡€é…ç½®ä¸é€šç”¨å‡½æ•°
# =============================================================================
st.set_page_config(page_title="äºšé©¬é€Šå…¨ç»´åˆ†æ (ç¨³å®šå¢å¼ºç‰ˆ)", layout="wide", page_icon="ğŸŒ")

st.title("ğŸŒ äºšé©¬é€Šå…¨ç»´åˆ†æç³»ç»Ÿï¼ˆç¨³å®šå¢å¼ºç‰ˆï¼‰")
st.markdown("""
**æœ¬ç‰ˆå¼ºåŒ–ç‚¹ï¼š**
1. âœ… **é™é»˜é”™è¯¯ä¿®å¤**ï¼šæ•°å€¼è§£æå¤±è´¥ä¸å†é»˜é»˜å˜ 0ï¼Œè€Œæ˜¯å˜ NaNï¼Œå¹¶ç»™å‡ºã€è§£æç‡è¯Šæ–­ã€‘æé†’ä½ ä¿®æ­£æ˜ å°„ã€‚
2. âœ… **è¯„åˆ†å¼ºæ ¡éªŒ**ï¼šè¯„åˆ†å¿…é¡»ç¬¦åˆ 0â€“5 æ˜Ÿåˆ†å¸ƒï¼Œå¦åˆ™è‡ªåŠ¨åˆ¤å®šâ€œåˆ—é€‰é”™â€ï¼ˆå¸¸è§ï¼šæŠŠè¯„è®ºæ•°/è¯„åˆ†æ•°å½“è¯„åˆ†ï¼‰ã€‚
3. âœ… **å›½å®¶/ä¾›åº”é“¾åˆ†æ**ï¼šè‡ªåŠ¨è¯†åˆ«å–å®¶å›½å®¶/æ‰€å±åœ°ï¼Œå¹¶å½’ä¸€åŒ–ç»Ÿè®¡ã€‚
4. âœ… **PRODUCT æ¨¡å—å‡çº§ä¸ºäº§å“å¼€å‘åˆ†æ**ï¼šæ–°å¢ SKU ç»“æ„ã€åŠŸæ•ˆ&æŠ€æœ¯è·¯çº¿ã€ä»·æ ¼é”šç‚¹ã€å†…å®¹å¯†åº¦ã€æˆç†Ÿåº¦è¯„åˆ†ã€å†³ç­–æ¸…å•ã€‚
""")

# --- é€šç”¨æ¸…æ´—å‡½æ•°ï¼šæ•°å€¼ï¼ˆå¤±è´¥=NaNï¼Œä¸åé”™ï¼‰---
def clean_numeric(val):
    """
    æ›´ç¨³å¥çš„æ•°å€¼æ¸…æ´—ï¼š
    - å¤±è´¥è¿”å› NaNï¼ˆå…³é”®ï¼šé¿å…é™é»˜é”™è¯¯ï¼‰
    - æ”¯æŒ $/Â¥/åƒåˆ†ä½/åŒºé—´ 10-20 æˆ– 10 to 20
    """
    if pd.isna(val):
        return np.nan
    s = str(val).strip()
    if s == "" or s.lower() in ["nan", "null"]:
        return np.nan

    s = s.replace("$", "").replace("Â¥", "").replace(",", "").replace(" ", "").replace("ï¿¥", "")
    # ç™¾åˆ†å·ï¼ˆå¦‚ä»½é¢ï¼‰
    if "%" in s:
        try:
            return float(s.replace("%", "")) / 100.0
        except Exception:
            return np.nan

    nums = re.findall(r"\d+(?:\.\d+)?", s)
    if not nums:
        return np.nan

    # åŒºé—´å–å‡å€¼
    if len(nums) >= 2 and ("-" in s or "to" in s.lower()):
        try:
            return (float(nums[0]) + float(nums[1])) / 2.0
        except Exception:
            return np.nan

    try:
        return float(nums[0])
    except Exception:
        return np.nan


def numeric_diagnose(series: pd.Series):
    """è¿”å›è§£æç‡ã€ä¸­ä½æ•°ã€P90ï¼ˆç”¨äºåˆ¤åˆ«å­—æ®µæ˜¯å¦é€‰é”™ï¼‰"""
    parsed = series.apply(clean_numeric)
    rate = float(parsed.notna().mean()) if len(parsed) else 0.0
    med = float(parsed.median()) if parsed.notna().any() else np.nan
    p90 = float(parsed.quantile(0.9)) if parsed.notna().any() else np.nan
    return rate, med, p90


def clean_country(val):
    """æ¸…æ´—å›½å®¶/åœ°åŒºä»£ç ï¼ˆå¯æŒ‰ä½ æ•°æ®ç»§ç»­æ‰©å±•ï¼‰"""
    if pd.isna(val):
        return "Unknown"
    s = str(val).strip().upper()

    # å¸¸è§å½’å¹¶
    if "CN" in s or "CHINA" in s or "HONG" in s or "HK" in s:
        return "CN (ä¸­å›½)"
    if "US" in s or "UNITED STATES" in s or "AMERICA" in s:
        return "US (ç¾å›½)"
    if "KR" in s or "KOREA" in s:
        return "KR (éŸ©å›½)"
    if "JP" in s or "JAPAN" in s:
        return "JP (æ—¥æœ¬)"
    if "DE" in s or "GERMANY" in s:
        return "DE (å¾·å›½)"
    if "UK" in s or "UNITED KINGDOM" in s or "BRITAIN" in s:
        return "UK (è‹±å›½)"
    if "FR" in s or "FRANCE" in s:
        return "FR (æ³•å›½)"
    if "IT" in s or "ITALY" in s:
        return "IT (æ„å¤§åˆ©)"
    if "CA" in s or "CANADA" in s:
        return "CA (åŠ æ‹¿å¤§)"

    return s


def find_col(columns, keywords):
    """æ¨¡ç³ŠæŸ¥æ‰¾åˆ—åï¼ˆåªåšåˆ—ååŒ¹é…ï¼›å‡†ç¡®æ€§ç”±åç»­è¯Šæ–­å…œåº•ï¼‰"""
    for col in columns:
        col_norm = str(col).lower().replace(" ", "")
        for kw in keywords:
            if kw.lower().replace(" ", "") in col_norm:
                return col
    return None


def safe_mode(series: pd.Series):
    """å®‰å…¨å–ä¼—æ•°ï¼Œé¿å…ç©ºåºåˆ—æŠ¥é”™"""
    s = series.dropna()
    if len(s) == 0:
        return np.nan
    try:
        return s.mode().iloc[0]
    except Exception:
        return s.iloc[0]


# =============================================================================
# 2. æ¨¡å¼è¯†åˆ«å¼•æ“ï¼ˆæ›´ç¨³ä¸€ç‚¹ï¼šé¿å…è¯¯åˆ¤ï¼‰
# =============================================================================
def detect_sheet_mode(df):
    cols = [str(c).lower() for c in df.columns]
    col_str = " ".join(cols)

    has_asin = ("asin" in col_str) or ("sku" in col_str)
    has_title = ("title" in col_str) or ("æ ‡é¢˜" in col_str) or ("name" in col_str) or ("å•†å“" in col_str)
    has_seller = ("seller" in col_str) or ("å–å®¶" in col_str)
    has_brand = ("brand" in col_str) or ("å“ç‰Œ" in col_str)
    has_share = ("share" in col_str) or ("ä»½é¢" in col_str)
    has_price_or_sales = ("price" in col_str) or ("ä»·æ ¼" in col_str) or ("sales" in col_str) or ("é”€é‡" in col_str)

    # PRODUCTï¼šå¿…é¡»æœ‰ï¼ˆASIN æˆ– Titleï¼‰ä¸”åŒæ—¶å…·å¤‡ä»·æ ¼/é”€é‡/è¯„åˆ†ç­‰ä»»æ„ä¸€ä¸ªâ€œäº¤æ˜“å­—æ®µâ€
    if (has_asin or has_title) and has_price_or_sales:
        return "PRODUCT"

    # SELLERï¼šæœ‰ seller ä¸”æ²¡æœ‰ asinï¼ˆå¦åˆ™é€šå¸¸æ˜¯äº§å“è¡¨åŒ…å« seller ä¿¡æ¯ï¼‰
    if has_seller and (not has_asin):
        return "SELLER"

    # BRANDï¼šæœ‰ brand ä¸”æœ‰ share/revenue è¿™ç±»æ±‡æ€»å­—æ®µ
    if has_brand and has_share:
        return "BRAND"

    return "GENERIC"


# =============================================================================
# 3. PRODUCT æ¨¡å—ï¼šäº§å“å¼€å‘æ¨¡å¼ï¼ˆå« 9 å¤§ç»´åº¦æ ¸å¿ƒï¼‰
# =============================================================================
def render_product_dashboard(df):
    st.info("ğŸ“¦ **äº§å“å¼€å‘æ¨¡å¼**ï¼ˆå«ä¾›åº”é“¾ + 9 å¤§ç»´åº¦ï¼‰")

    all_cols = df.columns.tolist()

    # 1) å­—æ®µæ˜ å°„ï¼ˆå« country/brand/asin ç­‰ï¼‰
    col_map = {
        "asin": find_col(all_cols, ["asin", "sku", "itemid", "äº§å“id", "å•†å“id"]),
        "title": find_col(all_cols, ["title", "æ ‡é¢˜", "name", "å•†å“å"]),
        "brand": find_col(all_cols, ["brand", "å“ç‰Œ", "manufacturer", "maker"]),
        "price": find_col(all_cols, ["price", "ä»·æ ¼", "å”®ä»·", "å‡ä»·", "currentprice", "buybox"]),
        "sales": find_col(all_cols, ["sales", "é”€é‡", "sold", "units", "orders"]),
        "revenue": find_col(all_cols, ["revenue", "é”€å”®é¢", "amount", "gmv"]),
        "rating": find_col(all_cols, ["rating", "è¯„åˆ†", "stars", "avg rating", "average rating"]),
        "reviews": find_col(all_cols, ["reviews", "è¯„è®ºæ•°", "è¯„ä»·æ•°", "ratings count", "review count", "è¯„åˆ†æ•°"]),
        "country": find_col(all_cols, ["country", "region", "å–å®¶æ‰€å±åœ°", "æ‰€å±åœ°", "å›½å®¶", "location", "origin"]),
        "size": find_col(all_cols, ["size", "å‡€å«é‡", "è§„æ ¼", "oz", "ml", "g", "gram", "ounce", "å®¹é‡"]),
        "flavor": find_col(all_cols, ["flavor", "å‘³", "é¦™å‹", "é¦™å‘³", "å£å‘³", "variant"]),
        "rank": find_col(all_cols, ["rank", "bsr", "best sellers", "æ’å"]),
    }

    # 2) æ˜ å°„æ‰‹åŠ¨ä¿®æ­£ï¼ˆä¸æ”¹å˜ä½ åŸç»“æ„ï¼šä¿ç•™â€œè‡ªåŠ¨ä¸ºä¸»ï¼Œæ‰‹åŠ¨ä¸ºè¾…â€ï¼‰
    with st.expander("ğŸ› ï¸ å­—æ®µæ˜ å°„è®¾ç½®ï¼ˆè¯†åˆ«ä¸å‡†ç‚¹è¿™é‡Œä¿®æ­£ï¼‰", expanded=False):
        cols = [None] + all_cols
        c1, c2, c3, c4 = st.columns(4)
        col_map["asin"] = c1.selectbox("ASIN/SKU", cols, index=cols.index(col_map["asin"]) if col_map["asin"] in cols else 0)
        col_map["title"] = c2.selectbox("æ ‡é¢˜/åç§° Title*", cols, index=cols.index(col_map["title"]) if col_map["title"] in cols else 0)
        col_map["brand"] = c3.selectbox("å“ç‰Œ Brand", cols, index=cols.index(col_map["brand"]) if col_map["brand"] in cols else 0)
        col_map["country"] = c4.selectbox("å–å®¶æ‰€å±åœ° Country/Region", cols, index=cols.index(col_map["country"]) if col_map["country"] in cols else 0)

        c5, c6, c7, c8 = st.columns(4)
        col_map["price"] = c5.selectbox("ä»·æ ¼ Price", cols, index=cols.index(col_map["price"]) if col_map["price"] in cols else 0)
        col_map["sales"] = c6.selectbox("é”€é‡ Sales/Units", cols, index=cols.index(col_map["sales"]) if col_map["sales"] in cols else 0)
        col_map["rating"] = c7.selectbox("è¯„åˆ† Rating(0-5)", cols, index=cols.index(col_map["rating"]) if col_map["rating"] in cols else 0)
        col_map["reviews"] = c8.selectbox("è¯„è®º/è¯„åˆ†æ•° Reviews/Count", cols, index=cols.index(col_map["reviews"]) if col_map["reviews"] in cols else 0)

        c9, c10, c11, c12 = st.columns(4)
        col_map["revenue"] = c9.selectbox("é”€å”®é¢ Revenue", cols, index=cols.index(col_map["revenue"]) if col_map["revenue"] in cols else 0)
        col_map["size"] = c10.selectbox("è§„æ ¼/å‡€å«é‡ Size", cols, index=cols.index(col_map["size"]) if col_map["size"] in cols else 0)
        col_map["flavor"] = c11.selectbox("å£å‘³/å˜ä½“ Flavor/Variant", cols, index=cols.index(col_map["flavor"]) if col_map["flavor"] in cols else 0)
        col_map["rank"] = c12.selectbox("æ’å/BSR Rank", cols, index=cols.index(col_map["rank"]) if col_map["rank"] in cols else 0)

    # 3) å¿…è¦å­—æ®µæ£€æŸ¥
    if not col_map["title"]:
        st.error("æ— æ³•åˆ†æï¼šç¼ºå°‘ã€æ ‡é¢˜/åç§°ã€‘åˆ—ï¼ˆTitleï¼‰ã€‚è¯·åœ¨æ˜ å°„è®¾ç½®ä¸­é€‰æ‹©æ­£ç¡®åˆ—ã€‚")
        return

    data = df.copy()
    data["Title_Str"] = data[col_map["title"]].astype(str)

    # 4) æ•°å€¼æ¸…æ´—ï¼ˆå¤±è´¥=NaNï¼Œåç»­ä¸ä¼šæ±¡æŸ“ç»Ÿè®¡ï¼‰
    if col_map["price"]:
        data["clean_price"] = data[col_map["price"]].apply(clean_numeric)
    else:
        data["clean_price"] = np.nan

    if col_map["sales"]:
        data["clean_sales"] = data[col_map["sales"]].apply(clean_numeric)
    else:
        data["clean_sales"] = np.nan

    if col_map["revenue"]:
        data["clean_revenue"] = data[col_map["revenue"]].apply(clean_numeric)
    else:
        data["clean_revenue"] = np.nan

    if col_map["rating"]:
        data["clean_rating"] = data[col_map["rating"]].apply(clean_numeric)
    else:
        data["clean_rating"] = np.nan

    if col_map["reviews"]:
        data["clean_reviews"] = data[col_map["reviews"]].apply(clean_numeric)
    else:
        data["clean_reviews"] = np.nan

    # 5) å›½å®¶/æ‰€å±åœ°æ¸…æ´—
    if col_map["country"]:
        data["_raw_country"] = data[col_map["country"]]
        data["Origin"] = data[col_map["country"]].apply(clean_country)
    else:
        data["_raw_country"] = np.nan
        data["Origin"] = "Unknown"

    # 6) è¯Šæ–­ï¼šè§£æç‡ / åˆç†æ€§æ ¡éªŒï¼ˆæŠŠé™é»˜é”™è¯¯å˜æˆå¯è¯Šæ–­ã€å¯ä¿®å¤ï¼‰
    with st.expander("ğŸ§ª æ•°æ®è¯Šæ–­ï¼ˆè§£æç‡/åˆç†æ€§æ ¡éªŒï¼‰", expanded=True):
        st.caption("å¦‚æœè¿™é‡Œå‡ºç°è§£æç‡å¾ˆä½æˆ–è¯„åˆ†ä¸åœ¨ 0â€“5ï¼Œè¯´æ˜åˆ—æ˜ å°„å¯èƒ½é€‰é”™ã€‚")

        # ä»·æ ¼è¯Šæ–­
        if col_map["price"]:
            r, med, p90 = numeric_diagnose(df[col_map["price"]])
            st.write(f"**ä»·æ ¼åˆ—**ï¼š`{col_map['price']}` | è§£æç‡={r:.1%} | ä¸­ä½æ•°={med:.2f} | P90={p90:.2f}")
            if r < 0.25 or (np.isfinite(med) and med > 300):
                st.warning("âš ï¸ ä»·æ ¼åˆ—ç–‘ä¼¼é€‰é”™ï¼ˆè§£æç‡è¿‡ä½æˆ–ä¸­ä½æ•°è¿‡å¤§ï¼‰ã€‚è¯·å›åˆ°å­—æ®µæ˜ å°„è®¾ç½®æ‰‹åŠ¨ä¿®æ­£ã€‚")
                # å±•ç¤ºéƒ¨åˆ†å¤±è´¥æ ·æœ¬
                parsed = df[col_map["price"]].apply(clean_numeric)
                bad = df.loc[parsed.isna(), col_map["price"]].dropna().astype(str).head(12)
                if len(bad):
                    st.write("ä»·æ ¼è§£æå¤±è´¥æ ·æœ¬ï¼ˆå‰ 12 æ¡ï¼Œè‹¥å‡ºç°å“ç‰Œ/æ ‡é¢˜ï¼Œè¯´æ˜é€‰é”™ï¼‰ï¼š")
                    st.dataframe(bad.to_frame("bad_samples"), use_container_width=True)
        else:
            st.info("â„¹ï¸ æœªé€‰æ‹©ä»·æ ¼åˆ—ï¼šä»·æ ¼ç›¸å…³åˆ†æä¼šç¼ºå¤±ã€‚")

        # è¯„åˆ†è¯Šæ–­ï¼ˆå¼ºæ ¡éªŒ 0â€“5ï¼‰
        if col_map["rating"]:
            r, med, p90 = numeric_diagnose(df[col_map["rating"]])
            st.write(f"**è¯„åˆ†åˆ—**ï¼š`{col_map['rating']}` | è§£æç‡={r:.1%} | ä¸­ä½æ•°={med:.2f} | P90={p90:.2f}")
            # å¼ºæ ¡éªŒï¼šå¦‚æœè¯„åˆ†åˆ†å¸ƒæ˜æ˜¾ä¸æ˜¯ 0-5ï¼Œç¦ç”¨è¯„åˆ†åˆ—
            if (not np.isfinite(med)) or med > 5.5 or p90 > 6.0:
                st.warning("âš ï¸ è¯„åˆ†åˆ—ç–‘ä¼¼é€‰é”™ï¼ˆå¸¸è§ï¼šæŠŠè¯„è®ºæ•°/è¯„åˆ†æ•°å½“è¯„åˆ†ï¼‰ã€‚æœ¬ Sheet å·²è‡ªåŠ¨ç¦ç”¨è¯„åˆ†åˆ†æã€‚")
                data["clean_rating"] = np.nan
                col_map["rating"] = None
        else:
            st.info("â„¹ï¸ æœªé€‰æ‹©è¯„åˆ†åˆ—ï¼šè¯„åˆ†ç›¸å…³åˆ†æä¼šç¼ºå¤±ã€‚")

        # é”€é‡è¯Šæ–­ï¼ˆä¸åšç¡¬é˜ˆå€¼ï¼Œåªæç¤ºè§£æç‡ï¼‰
        if col_map["sales"]:
            r, med, p90 = numeric_diagnose(df[col_map["sales"]])
            st.write(f"**é”€é‡åˆ—**ï¼š`{col_map['sales']}` | è§£æç‡={r:.1%} | ä¸­ä½æ•°={med:.2f} | P90={p90:.2f}")
            if r < 0.25:
                st.warning("âš ï¸ é”€é‡åˆ—è§£æç‡è¾ƒä½ï¼Œå¯èƒ½é€‰é”™æˆ–æ•°æ®ä¸ºéç»“æ„åŒ–æ–‡æœ¬ã€‚")
        else:
            st.info("â„¹ï¸ æœªé€‰æ‹©é”€é‡åˆ—ï¼šé”€é‡ç›¸å…³åˆ†æä¼šç¼ºå¤±ã€‚")

        # è¯„è®º/è¯„åˆ†æ•°è¯Šæ–­
        if col_map["reviews"]:
            r, med, p90 = numeric_diagnose(df[col_map["reviews"]])
            st.write(f"**è¯„è®º/è¯„åˆ†æ•°åˆ—**ï¼š`{col_map['reviews']}` | è§£æç‡={r:.1%} | ä¸­ä½æ•°={med:.2f} | P90={p90:.2f}")
        else:
            st.info("â„¹ï¸ æœªé€‰æ‹©è¯„è®º/è¯„åˆ†æ•°åˆ—ï¼šå¯ç”¨äºâ€œéœ€æ±‚ä»£ç†â€çš„å£å¾„ä¼šç¼ºå¤±ã€‚")

    # =============================================================================
    # 7) 9 å¤§ç»´åº¦ï¼šå­—æ®µæŠ½å–ä¸æ´¾ç”Ÿ
    # =============================================================================

    # --- ç»´åº¦ä¸€ï¼šSKUç»“æ„ï¼ˆPack / è§„æ ¼ / Flavor / ASINï¼‰ ---
    def extract_pack(title: str) -> int:
        t = str(title).lower()
        m = re.search(r"(pack\s*of\s*\d+|\d+\s*pack\b|\d+\s*count\b|\bx\s*\d+)", t)
        if m:
            nums = re.findall(r"\d+", m.group(0))
            return int(nums[0]) if nums else 1
        return 1

    data["Pack_Count"] = data["Title_Str"].apply(extract_pack)
    data["Is_Multipack"] = data["Pack_Count"] > 1

    # flavorï¼šä¼˜å…ˆåˆ—ï¼Œå¦åˆ™ä»æ ‡é¢˜ç²—æå–ï¼ˆå¯æŒ‰ä½ çš„å“ç±»æ¢è¯åº“ï¼‰
    FLAVOR_KW = ["mint", "spearmint", "peppermint", "cinnamon", "strawberry", "bubblegum", "lemon", "orange"]
    if col_map["flavor"]:
        data["Flavor"] = data[col_map["flavor"]].astype(str)
    else:
        def extract_flavor_from_title(t: str):
            tl = str(t).lower()
            hits = [k for k in FLAVOR_KW if k in tl]
            return hits[0] if hits else np.nan
        data["Flavor"] = data["Title_Str"].apply(extract_flavor_from_title)

    # sizeï¼šå¦‚æœæ²¡æœ‰ size åˆ—ï¼Œå¯ä»æ ‡é¢˜æŠ“å¸¸è§è§„æ ¼ï¼ˆoz/g/mlï¼‰
    def extract_size_str(t: str):
        tl = str(t).lower()
        m = re.search(r"(\d+(?:\.\d+)?)\s*(oz|ounce|ounces|g|gram|grams|ml|l)\b", tl)
        if m:
            return f"{m.group(1)} {m.group(2)}"
        return np.nan

    if col_map["size"]:
        data["Size_Str"] = data[col_map["size"]].astype(str)
    else:
        data["Size_Str"] = data["Title_Str"].apply(extract_size_str)

    # --- ç»´åº¦äºŒï¼šåŠŸæ•ˆä¸æŠ€æœ¯è·¯çº¿ ---
    TECH_KW = ["nano", "hydroxyapatite", "hap", "fluoride-free", "fluoride free", "xylitol", "charcoal", "probiotic", "biomimetic"]
    EFF_KW = ["remineral", "remineralization", "sensitivity", "sensitive", "whitening", "stain", "enamel", "gum", "fresh breath", "cavity", "plaque", "tartar", "repair"]

    def extract_kw_list(text: str, kws):
        tl = str(text).lower()
        return [k for k in kws if k in tl]

    data["Tech_Tags"] = data["Title_Str"].apply(lambda x: extract_kw_list(x, TECH_KW))
    data["Eff_Tags"] = data["Title_Str"].apply(lambda x: extract_kw_list(x, EFF_KW))

    data["Tech_Main"] = data["Tech_Tags"].apply(lambda x: x[0] if isinstance(x, list) and len(x) else np.nan)
    data["Eff_Main"] = data["Eff_Tags"].apply(lambda x: x[0] if isinstance(x, list) and len(x) else np.nan)

    # --- ç»´åº¦ä¸‰ï¼šä»·æ ¼å¸¦ & é”šç‚¹ ---
    data["Price_Band"] = pd.cut(
        data["clean_price"],
        bins=[0, 10, 15, 20, 30, 1000],
        labels=["<10", "10-15", "15-20", "20-30", "30+"]
    )

    # å•æ”¯ä»·ï¼ˆPack åï¼‰
    data["Unit_Price_per_item"] = np.where(
        data["clean_price"].notna() & (data["Pack_Count"] > 0),
        data["clean_price"] / data["Pack_Count"].replace(0, np.nan),
        np.nan
    )

    # --- ç»´åº¦å››ï¼šå“ç‰Œå®šä½ä¸èƒŒä¹¦å¼ºåº¦ ---
    MEDICAL_KW = ["doctor", "dr.", "clinical", "health", "professional", "dentist"]
    if col_map["brand"]:
        data["Brand_Str"] = data[col_map["brand"]].astype(str)
        data["Brand_Type"] = data["Brand_Str"].str.lower().apply(
            lambda x: "Medical/Functional" if any(k in x for k in MEDICAL_KW) else "Consumer"
        )
    else:
        data["Brand_Str"] = np.nan
        data["Brand_Type"] = "Unknown"

    # --- ç»´åº¦äº”ï¼šåŒ…è£…ä½“ç§¯ & FBAé£é™©ï¼ˆç®€åŒ– proxyï¼šå¤šæ”¯è£…å¯èƒ½è§¦å‘ï¼‰ ---
    data["FBA_Risk_Flag"] = data["Pack_Count"] >= 3

    # --- ç»´åº¦å…­ï¼šå†…å®¹è¡¨è¾¾ä¸å–ç‚¹å¯†åº¦ ---
    data["Title_Length"] = data["Title_Str"].str.len()
    data["Selling_Point_Count"] = data["Title_Str"].apply(
        lambda x: int(sum([(k in str(x).lower()) for k in (TECH_KW + EFF_KW)]))
    )
    data["Is_Tech_Heavy"] = data["Tech_Tags"].apply(lambda x: len(x) >= 2)

    # --- ç»´åº¦ä¸ƒï¼šæ¸ é“ç­–ç•¥ï¼ˆproxyï¼šé”€é‡é›†ä¸­åº¦ / æ’åå¦‚æœ‰ï¼‰ ---
    if data["clean_sales"].notna().any():
        total_sales = data["clean_sales"].sum(skipna=True)
        top10_sales = data.sort_values("clean_sales", ascending=False).head(10)["clean_sales"].sum(skipna=True)
        sales_concentration_top10 = float(top10_sales / total_sales) if total_sales and total_sales > 0 else np.nan
    else:
        sales_concentration_top10 = np.nan

    # --- ç»´åº¦å…«ï¼šå¸‚åœºæˆç†Ÿåº¦ï¼ˆç»¼åˆè¯„åˆ†ï¼šè§„åˆ™å¯è°ƒï¼‰ ---
    # ä»·æ ¼æ”¶æ•›ï¼šstd è¶Šå°è¶Šæˆç†Ÿï¼›æŠ€æœ¯é›†ä¸­ï¼šä¸»æŠ€æœ¯å æ¯”è¶Šé«˜è¶Šæˆç†Ÿï¼›SKUæ ‡å‡†åŒ–ï¼špack ç§ç±»è¶Šå°‘è¶Šæˆç†Ÿ
    price_std = float(data["clean_price"].std(skipna=True)) if data["clean_price"].notna().any() else np.nan
    tech_mode_share = np.nan
    if data["Tech_Main"].notna().any():
        tech_mode_share = float(data["Tech_Main"].value_counts(normalize=True, dropna=True).iloc[0])
    pack_unique = int(data["Pack_Count"].nunique(dropna=True))

    # æ„é€ ä¸€ä¸ª 0-100 çš„â€œæˆç†Ÿåº¦åˆ†â€ï¼ˆè¶Šé«˜è¶Šæˆç†Ÿï¼‰
    # ç»éªŒè§„åˆ™ï¼šå¯æŒ‰ç±»ç›®å¾®è°ƒ
    score = 0
    if np.isfinite(price_std):
        # std <=5 è®°æ›´æˆç†Ÿ
        score += 35 if price_std <= 5 else (20 if price_std <= 10 else 10)
    else:
        score += 10

    if np.isfinite(tech_mode_share):
        score += 35 if tech_mode_share >= 0.5 else (20 if tech_mode_share >= 0.3 else 10)
    else:
        score += 10

    score += 30 if pack_unique <= 3 else (20 if pack_unique <= 6 else 10)
    market_maturity_score = int(min(max(score, 0), 100))

    # --- ç»´åº¦ä¹ï¼šå¯åæ¨çš„å¼€å‘å†³ç­–æ¸…å•ï¼ˆTab å†…è¾“å‡ºï¼‰ ---

    # =============================================================================
    # 8) KPI æŒ‡æ ‡å¡ï¼ˆä»…ç”¨æœ‰æ•ˆå€¼ï¼Œé¿å… NaN æ±¡æŸ“ï¼‰
    # =============================================================================
    k1, k2, k3, k4 = st.columns(4)
    # æ€»é”€é‡ï¼ˆæœ‰æ•ˆï¼‰
    total_sales_val = float(data["clean_sales"].sum(skipna=True)) if data["clean_sales"].notna().any() else 0.0
    avg_price_val = float(data["clean_price"].mean(skipna=True)) if data["clean_price"].notna().any() else np.nan
    # é”€å”®é¢ï¼šä¼˜å…ˆç”¨ clean_revenueï¼Œå¦åˆ™ç”¨ sales*price
    if data["clean_revenue"].notna().any():
        total_rev_val = float(data["clean_revenue"].sum(skipna=True))
        rev_label = "æ€»é”€å”®é¢"
    elif data["clean_sales"].notna().any() and data["clean_price"].notna().any():
        total_rev_val = float((data["clean_sales"] * data["clean_price"]).sum(skipna=True))
        rev_label = "é¢„ä¼°é”€å”®é¢"
    else:
        total_rev_val = np.nan
        rev_label = "é”€å”®é¢"

    avg_rating_val = float(data["clean_rating"].mean(skipna=True)) if data["clean_rating"].notna().any() else np.nan
    demand_proxy = float(data["clean_reviews"].sum(skipna=True)) if data["clean_reviews"].notna().any() else np.nan

    k1.metric("SKUæ•°", f"{len(data):,}")
    k2.metric("æ€»é”€é‡ï¼ˆæœ‰æ•ˆï¼‰", f"{total_sales_val:,.0f}")
    k3.metric(rev_label, f"${total_rev_val:,.0f}" if np.isfinite(total_rev_val) else "N/A")
    k4.metric("å¹³å‡è¯„åˆ†ï¼ˆæœ‰æ•ˆï¼‰", f"{avg_rating_val:.2f} â­" if np.isfinite(avg_rating_val) else "N/A")

    # =============================================================================
    # 9) å¯è§†åŒ– Tabsï¼ˆä¿æŒä½ åŸ Tab æ€è·¯ï¼Œä½†å¢å¼ºå†…å®¹ï¼‰
    # =============================================================================
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "ğŸŒ ä¾›åº”é“¾ä¸å›½å®¶",
        "ğŸ“¦ SKUç»“æ„&å½¢æ€",
        "ğŸ§ª åŠŸæ•ˆ&æŠ€æœ¯è·¯çº¿",
        "ğŸ’° ä»·æ ¼ä½“ç³»&é”šç‚¹",
        "ğŸ—£ï¸ è¡¨è¾¾å¯†åº¦&å†…å®¹ç­–ç•¥",
        "âœ… å†³ç­–å»ºè®®"
    ])

    # ---------------------------
    # Tab1: ä¾›åº”é“¾ä¸å›½å®¶
    # ---------------------------
    with tab1:
        st.subheader("ä¾›åº”é“¾æºå¤´åˆ†æï¼ˆSeller Location / Originï¼‰")

        if col_map["country"]:
            c1, c2 = st.columns(2)

            with c1:
                origin_counts = data["Origin"].value_counts(dropna=False).reset_index()
                origin_counts.columns = ["Origin", "Count"]
                fig = px.pie(origin_counts, values="Count", names="Origin",
                             title="å–å®¶æ‰€å±åœ°åˆ†å¸ƒï¼ˆSKUæ•°é‡ï¼‰", hole=0.4)
                st.plotly_chart(fig, use_container_width=True)

            with c2:
                price_by_country = data.groupby("Origin", dropna=False)["clean_price"].mean(skipna=True).reset_index()
                fig2 = px.bar(price_by_country, x="Origin", y="clean_price",
                              title="ä¸åŒæ‰€å±åœ°å–å®¶çš„å¹³å‡å”®ä»·ï¼ˆæœ‰æ•ˆä»·æ ¼ï¼‰", color="Origin")
                st.plotly_chart(fig2, use_container_width=True)

            cn_ratio = float((data["Origin"].astype(str).str.contains("CN")).mean())
            if cn_ratio > 0.6:
                st.warning(f"ğŸ”´ ä¾›åº”é“¾é¢„è­¦ï¼šä¸­å›½å–å®¶å æ¯” {cn_ratio:.1%}ã€‚é€šå¸¸æ„å‘³ç€ä¾›åº”é“¾æˆç†Ÿã€ä»·æ ¼æˆ˜æ›´æ¿€çƒˆã€‚")
            elif cn_ratio < 0.2:
                st.success(f"ğŸŸ¢ æœºä¼šä¿¡å·ï¼šä¸­å›½å–å®¶å æ¯” {cn_ratio:.1%}ã€‚æœ¬åœŸå“ç‰Œä¸ºä¸»ï¼Œå¯èƒ½å­˜åœ¨ä¾›åº”é“¾é™æœ¬åˆ‡å…¥æœºä¼šã€‚")
            else:
                st.info(f"ğŸŸ¡ ä¸­æ€§ï¼šCN å æ¯” {cn_ratio:.1%}ã€‚éœ€è¦ç»“åˆä»·æ ¼å¸¦/å“ç‰Œç±»å‹è¿›ä¸€æ­¥åˆ¤æ–­ã€‚")
        else:
            st.warning("âš ï¸ æœªæ£€æµ‹åˆ° Country/Region/æ‰€å±åœ°åˆ—ã€‚è¯·åœ¨å­—æ®µæ˜ å°„è®¾ç½®é‡Œæ‰‹åŠ¨é€‰æ‹©æ­£ç¡®åˆ—ã€‚")

        st.markdown("#### éœ€æ±‚ä»£ç†å£å¾„æç¤º")
        if np.isfinite(demand_proxy):
            st.write(f"å½“å‰ä½¿ç”¨ `è¯„è®º/è¯„åˆ†æ•°` ä½œä¸ºéœ€æ±‚ä»£ç†ï¼ˆæ€»é‡={demand_proxy:,.0f}ï¼‰ã€‚")
        else:
            st.write("æœªæä¾›è¯„è®º/è¯„åˆ†æ•°åˆ—ï¼šå»ºè®®è¡¥å…… Reviews/Rating Countï¼Œç”¨äºæ›´ç¨³å¥çš„éœ€æ±‚ä»£ç†åˆ¤æ–­ã€‚")

    # ---------------------------
    # Tab2: SKUç»“æ„ & å½¢æ€
    # ---------------------------
    with tab2:
        st.subheader("äº§å“å½¢æ€ä¸ SKU ç»“æ„ï¼ˆProduct Architectureï¼‰")

        c1, c2 = st.columns(2)
        with c1:
            # Pack åˆ†å¸ƒï¼šç”¨é”€é‡åŠ æƒä¼˜å…ˆï¼Œå¦åˆ™ç”¨SKUè®¡æ•°
            if data["clean_sales"].notna().any():
                pack_dist = data.groupby("Pack_Count")["clean_sales"].sum(skipna=True).reset_index()
                fig = px.bar(pack_dist, x="Pack_Count", y="clean_sales",
                             title="Pack æ•°åˆ†å¸ƒï¼ˆæŒ‰é”€é‡åŠ æƒï¼‰")
            else:
                pack_cnt = data["Pack_Count"].value_counts().reset_index()
                pack_cnt.columns = ["Pack_Count", "Count"]
                fig = px.bar(pack_cnt, x="Pack_Count", y="Count",
                             title="Pack æ•°åˆ†å¸ƒï¼ˆæŒ‰SKUæ•°é‡ï¼‰")
            st.plotly_chart(fig, use_container_width=True)

        with c2:
            # Flavor åˆ†å¸ƒï¼ˆè‹¥å¯ç”¨ï¼‰
            flav = data["Flavor"].dropna()
            if len(flav):
                top_flavor = flav.value_counts().head(15).reset_index()
                top_flavor.columns = ["Flavor", "Count"]
                fig2 = px.bar(top_flavor, x="Count", y="Flavor", orientation="h",
                              title="å£å‘³/å˜ä½“ Top15ï¼ˆè®¡æ•°ï¼‰")
                st.plotly_chart(fig2, use_container_width=True)
            else:
                st.info("æœªè¯†åˆ«åˆ° Flavorï¼šå¦‚æ•°æ®é‡Œæœ‰å˜ä½“åˆ—è¯·åœ¨æ˜ å°„ä¸­é€‰æ‹© Flavor/Variantã€‚")

        st.markdown("#### å¤šæ”¯è£…æ˜¯å¦æ‰¿æ‹…å®¢å•ä»·/æ‘Šè–„æˆæœ¬ï¼Ÿ")
        tmp = data.dropna(subset=["clean_price"]).copy()
        if len(tmp):
            tmp["Unit_Price_per_item"] = tmp["clean_price"] / tmp["Pack_Count"].replace(0, np.nan)
            g = tmp.groupby("Is_Multipack").agg(
                SKUæ•°=("Title_Str", "size"),
                å‡ä»·=("clean_price", "mean"),
                å•æ”¯å‡ä»·=("Unit_Price_per_item", "mean")
            ).reset_index()
            g["Is_Multipack"] = g["Is_Multipack"].map({True: "Multipack", False: "Single"})
            st.dataframe(g, use_container_width=True)
        else:
            st.info("ä»·æ ¼ä¸å¯ç”¨ï¼šæ— æ³•è®¡ç®—å•æ”¯å‡ä»·ã€‚")

        st.markdown("#### è§„æ ¼ï¼ˆSizeï¼‰å¯ç”¨æ€§")
        non_empty_size = data["Size_Str"].astype(str).str.strip()
        st.write(f"å¯è§£æ/å¯è§è§„æ ¼å­—æ®µå æ¯”ï¼ˆéç©ºï¼‰ï¼š{(non_empty_size != 'nan').mean():.1%}")

    # ---------------------------
    # Tab3: åŠŸæ•ˆ & æŠ€æœ¯è·¯çº¿
    # ---------------------------
    with tab3:
        st.subheader("åŠŸæ•ˆä¸æŠ€æœ¯è·¯çº¿ï¼ˆEfficacy & Tech Routeï¼‰")

        c1, c2 = st.columns(2)
        with c1:
            eff = data["Eff_Main"].dropna()
            if len(eff):
                eff_hot = eff.value_counts().head(15).reset_index()
                eff_hot.columns = ["Efficacy", "Count"]
                fig = px.bar(eff_hot, x="Count", y="Efficacy", orientation="h", title="åŠŸæ•ˆä¸»è¯ Top15ï¼ˆè®¡æ•°ï¼‰")
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("æ ‡é¢˜ä¸­æœªåŒ¹é…åˆ°åŠŸæ•ˆå…³é”®è¯ï¼ˆå¯æ‰©å±• EFF_KW è¯åº“ï¼‰ã€‚")

        with c2:
            tech = data["Tech_Main"].dropna()
            if len(tech):
                tech_hot = tech.value_counts().head(15).reset_index()
                tech_hot.columns = ["Tech", "Count"]
                fig = px.bar(tech_hot, x="Count", y="Tech", orientation="h", title="æŠ€æœ¯ä¸»è¯ Top15ï¼ˆè®¡æ•°ï¼‰")
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("æ ‡é¢˜ä¸­æœªåŒ¹é…åˆ°æŠ€æœ¯å…³é”®è¯ï¼ˆå¯æ‰©å±• TECH_KW è¯åº“ï¼‰ã€‚")

        st.markdown("#### æŠ€æœ¯/åŠŸæ•ˆæ˜¯å¦åŒè´¨åŒ–ï¼Ÿï¼ˆé›†ä¸­åº¦ï¼‰")
        if data["Tech_Main"].notna().any():
            top_share = float(data["Tech_Main"].value_counts(normalize=True, dropna=True).iloc[0])
            st.write(f"æŠ€æœ¯ä¸»è¯ Top1 å æ¯”ï¼š**{top_share:.1%}**ï¼ˆè¶Šé«˜=è¶ŠåŒè´¨åŒ–/è¶Šæˆç†Ÿï¼‰")
        else:
            st.write("æŠ€æœ¯ä¸»è¯ä¸å¯ç”¨ã€‚")

        if data["Eff_Main"].notna().any():
            top_share2 = float(data["Eff_Main"].value_counts(normalize=True, dropna=True).iloc[0])
            st.write(f"åŠŸæ•ˆä¸»è¯ Top1 å æ¯”ï¼š**{top_share2:.1%}**ï¼ˆè¶Šé«˜=è¶Šé›†ä¸­ï¼‰")
        else:
            st.write("åŠŸæ•ˆä¸»è¯ä¸å¯ç”¨ã€‚")

        st.markdown("#### æŠ€æœ¯å™äº‹æ˜¯å¦æ”¯æ’‘æº¢ä»·ï¼Ÿï¼ˆTech vs Priceï¼‰")
        tmp = data.dropna(subset=["clean_price"]).copy()
        if len(tmp) and tmp["Tech_Main"].notna().any():
            g = tmp.groupby("Tech_Main")["clean_price"].mean().dropna().sort_values(ascending=False).head(15).reset_index()
            fig = px.bar(g, x="clean_price", y="Tech_Main", orientation="h", title="ä¸åŒæŠ€æœ¯ä¸»è¯çš„å¹³å‡å”®ä»·ï¼ˆæœ‰æ•ˆä»·æ ¼ï¼‰")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("ä»·æ ¼æˆ–æŠ€æœ¯æ ‡ç­¾ä¸å¯ç”¨ï¼Œæ— æ³•åšæŠ€æœ¯æº¢ä»·å¯¹æ¯”ã€‚")

    # ---------------------------
    # Tab4: ä»·æ ¼ä½“ç³» & é”šç‚¹
    # ---------------------------
    with tab4:
        st.subheader("ä»·æ ¼å¸¦ & ä»·å€¼é”šç‚¹ï¼ˆPrice Architectureï¼‰")

        if data["clean_price"].notna().any():
            fig = px.histogram(data.dropna(subset=["clean_price"]), x="clean_price", nbins=25,
                               title="å”®ä»·åŒºé—´åˆ†å¸ƒï¼ˆæœ‰æ•ˆä»·æ ¼ï¼‰", color="Origin")
            st.plotly_chart(fig, use_container_width=True)

            # ä»·æ ¼å¸¦ï¼ˆSKUè®¡æ•°ï¼‰
            band = data.groupby("Price_Band", dropna=False)["Title_Str"].size().reset_index()
            band.columns = ["Price_Band", "SKU_Count"]
            fig2 = px.bar(band, x="Price_Band", y="SKU_Count", title="ä»·æ ¼å¸¦åˆ†å¸ƒï¼ˆSKUæ•°é‡ï¼‰")
            st.plotly_chart(fig2, use_container_width=True)

            # å•æ”¯ä»·åˆ†å¸ƒï¼ˆå¦‚æœ pack æå–æœ‰æ•ˆï¼‰
            tmp = data.dropna(subset=["Unit_Price_per_item"]).copy()
            if len(tmp):
                fig3 = px.histogram(tmp, x="Unit_Price_per_item", nbins=25, title="å•æ”¯ä»·æ ¼åˆ†å¸ƒï¼ˆä»·æ ¼/Packï¼‰")
                st.plotly_chart(fig3, use_container_width=True)
        else:
            st.warning("âš ï¸ ä»·æ ¼ä¸å¯ç”¨ï¼šè¯·ä¿®æ­£ Price åˆ—æ˜ å°„æˆ–æ£€æŸ¥æ•°æ®æºã€‚")

        st.markdown("#### é«˜ä»·ä½æ˜¯å¦ç»‘å®šä¸“ä¸šèƒŒä¹¦ï¼Ÿï¼ˆBrand Type vs Priceï¼‰")
        tmp = data.dropna(subset=["clean_price"]).copy()
        if len(tmp) and "Brand_Type" in tmp.columns:
            g = tmp.groupby("Brand_Type")["clean_price"].mean().reset_index()
            fig = px.bar(g, x="Brand_Type", y="clean_price", title="ä¸åŒå“ç‰Œå®šä½çš„å¹³å‡å”®ä»·ï¼ˆæœ‰æ•ˆä»·æ ¼ï¼‰")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("ç¼ºå°‘å“ç‰Œæˆ–ä»·æ ¼æ•°æ®ï¼Œæ— æ³•åˆ¤æ–­èƒŒä¹¦ä¸ä»·æ ¼ç»‘å®šå…³ç³»ã€‚")

    # ---------------------------
    # Tab5: å†…å®¹è¡¨è¾¾ & å–ç‚¹å¯†åº¦
    # ---------------------------
    with tab5:
        st.subheader("å†…å®¹è¡¨è¾¾ä¸å–ç‚¹å¯†åº¦ï¼ˆMessaging Strategyï¼‰")

        c1, c2 = st.columns(2)
        with c1:
            fig = px.histogram(data, x="Title_Length", nbins=30, title="æ ‡é¢˜é•¿åº¦åˆ†å¸ƒ")
            st.plotly_chart(fig, use_container_width=True)
        with c2:
            fig = px.histogram(data, x="Selling_Point_Count", nbins=15, title="æ ‡é¢˜å–ç‚¹æ•°é‡åˆ†å¸ƒï¼ˆæŠ€æœ¯+åŠŸæ•ˆè¯å‘½ä¸­æ•°ï¼‰")
            st.plotly_chart(fig, use_container_width=True)

        st.markdown("#### æ˜¯å¦å­˜åœ¨â€œè¯´ä¸æ¸…ä½†å–å¾—å¥½â€çš„äº§å“ï¼Ÿï¼ˆçŸ­æ ‡é¢˜+é«˜é”€é‡ï¼‰")
        if data["clean_sales"].notna().any():
            tmp = data.dropna(subset=["clean_sales"]).copy()
            tmp = tmp[tmp["clean_sales"] > 0]
            if len(tmp):
                tmp["short_title_flag"] = tmp["Title_Length"] <= tmp["Title_Length"].median()
                # å€™é€‰ï¼šçŸ­æ ‡é¢˜ & é«˜é”€é‡ï¼ˆTop20%ï¼‰
                q = tmp["clean_sales"].quantile(0.8)
                cand = tmp[(tmp["short_title_flag"]) & (tmp["clean_sales"] >= q)].copy()
                cand = cand.sort_values("clean_sales", ascending=False).head(15)

                if len(cand):
                    show_cols = ["Title_Str", "clean_sales", "clean_price", "Origin", "Selling_Point_Count", "Title_Length", "Tech_Main", "Eff_Main"]
                    st.dataframe(cand[show_cols], use_container_width=True, height=360)
                    st.info("è¿™äº› SKU å¯èƒ½å…·å¤‡ï¼šè¡¨è¾¾æ›´ç®€æ´ï¼Œä½†ä¾æ—§å–å¾—å¥½ï¼ˆå¯èƒ½ä¾èµ–å“ç‰Œ/æ¸ é“/å¤–éƒ¨èƒŒä¹¦/å¼ºéœ€æ±‚ï¼‰ã€‚")
                else:
                    st.write("æœªå‘ç°æ˜æ˜¾çš„â€œçŸ­æ ‡é¢˜+é«˜é”€é‡â€å€™é€‰ã€‚")
        else:
            st.info("æœªæä¾›é”€é‡åˆ—ï¼šæ— æ³•åšâ€œè¯´ä¸æ¸…ä½†å–å¾—å¥½â€è¯†åˆ«ã€‚")

        st.markdown("#### é«˜é¢‘è¯ï¼ˆç²—ç•¥ï¼‰")
        text = " ".join(data["Title_Str"].tolist()).lower()
        stop = set(["toothpaste", "with", "pack", "count", "ounce", "oz", "ml", "gram", "grams", "and", "for", "the"])
        words = [w for w in re.split(r"\W+", text) if len(w) > 3 and w not in stop]
        top_words = pd.Series(words).value_counts().head(20)
        st.bar_chart(top_words)

    # ---------------------------
    # Tab6: å†³ç­–å»ºè®®ï¼ˆè¾“å‡ºâ€œå¼€å‘å†³ç­–æ¸…å•â€ï¼‰
    # ---------------------------
    with tab6:
        st.subheader("ğŸ¤– äº§å“å¼€å‘å†³ç­–æ¸…å•ï¼ˆå¯ç›´æ¥å†™è¿›ç«‹é¡¹ï¼‰")

        # å¤šè§„æ ¼åˆ¤æ–­ï¼šå¤šæ”¯è£…é”€é‡å æ¯” / SKUå æ¯”
        multi_sales_share = np.nan
        if data["clean_sales"].notna().any():
            s_total = data["clean_sales"].sum(skipna=True)
            s_multi = data.loc[data["Is_Multipack"], "clean_sales"].sum(skipna=True)
            multi_sales_share = float(s_multi / s_total) if s_total and s_total > 0 else np.nan
        multi_sku_share = float(data["Is_Multipack"].mean()) if len(data) else np.nan

        # æŠ€æœ¯åŒ–åˆ¤æ–­ï¼šæŠ€æœ¯æ ‡ç­¾è¦†ç›– & tech-heavy å æ¯”
        tech_cover = float(data["Tech_Main"].notna().mean()) if len(data) else np.nan
        tech_heavy = float(data["Is_Tech_Heavy"].mean()) if len(data) else np.nan

        # ä¸“ä¸šèƒŒä¹¦å æ¯”
        med_share = float((data["Brand_Type"] == "Medical/Functional").mean()) if "Brand_Type" in data.columns else np.nan

        # ä»·æ ¼é”šç‚¹ï¼ˆä¸­ä½æ•°ï¼‰
        price_median = float(data["clean_price"].median()) if data["clean_price"].notna().any() else np.nan

        # æˆç†Ÿåº¦ç»“è®º
        if market_maturity_score >= 70:
            maturity_txt = "åæˆç†Ÿï¼ˆæ‹¼æ‰§è¡Œ/æ¸ é“/æˆæœ¬ï¼‰"
        elif market_maturity_score >= 45:
            maturity_txt = "ä¸­ç­‰æˆç†Ÿï¼ˆä»å¯å·®å¼‚åŒ–åˆ‡å…¥ï¼‰"
        else:
            maturity_txt = "ç›¸å¯¹æ—©æœŸï¼ˆé€šè¿‡ä½“éªŒ/æŠ€æœ¯/å™äº‹éƒ½æœ‰æœºä¼šï¼‰"

        # æ¸ é“ä¾èµ– proxy
        if np.isfinite(sales_concentration_top10):
            if sales_concentration_top10 >= 0.6:
                channel_txt = "å¤´éƒ¨é«˜åº¦é›†ä¸­ï¼ˆæ›´åå¹¿å‘Š/èµ„æºé©±åŠ¨ï¼Œè¿›å…¥é—¨æ§›æ›´é«˜ï¼‰"
            elif sales_concentration_top10 >= 0.4:
                channel_txt = "å¤´éƒ¨ä¸­åº¦é›†ä¸­ï¼ˆæ—¢è¦æŠ•æ”¾ï¼Œä¹Ÿè¦äº§å“ç¡¬å·®å¼‚ï¼‰"
            else:
                channel_txt = "å¤´éƒ¨åˆ†æ•£ï¼ˆæ›´å¯èƒ½è‡ªç„¶æµé‡ä¹Ÿèƒ½è·‘ï¼Œäº§å“å·®å¼‚æ˜¯å…³é”®ï¼‰"
        else:
            channel_txt = "ç¼ºå°‘é”€é‡ï¼Œæ— æ³•åˆ¤æ–­æ¸ é“é›†ä¸­åº¦"

        st.markdown("### 1) æˆ‘ä»¬è¦ä¸è¦åšå¤šè§„æ ¼ï¼Ÿ")
        if np.isfinite(multi_sales_share):
            if multi_sales_share >= 0.4:
                st.success(f"å»ºè®®ï¼š**è¦åš**ï¼ˆå¤šæ”¯è£…é”€é‡å æ¯” {multi_sales_share:.1%}ï¼Œè¯´æ˜å¤šè§„æ ¼æ˜¯çœŸéœ€æ±‚/å¼ºè¿è¥å·¥å…·ï¼‰")
            else:
                st.info(f"å»ºè®®ï¼š**é¦–å‘å¯å…ˆå•è§„æ ¼**ï¼ˆå¤šæ”¯è£…é”€é‡å æ¯” {multi_sales_share:.1%}ï¼Œå¤šæ”¯è£…æ›´åƒåç»­æ‹‰å®¢å•å·¥å…·ï¼‰")
        else:
            # æ²¡é”€é‡ï¼Œç”¨SKUå æ¯”
            if np.isfinite(multi_sku_share) and multi_sku_share >= 0.3:
                st.info(f"å»ºè®®ï¼šå€¾å‘åšï¼ˆå¤šæ”¯è£… SKU å æ¯” {multi_sku_share:.1%}ï¼‰ï¼Œä½†å»ºè®®è¡¥å……é”€é‡/è¯„è®ºä½œä¸ºæ ¡éªŒã€‚")
            else:
                st.info("å»ºè®®ï¼šå…ˆå•è§„æ ¼è¯•æ°´ï¼ˆç¼ºé”€é‡/è¯„è®ºæ•°æ®ï¼Œè°¨æ…ä¸€æ¬¡ä¸Šå¤ªå¤šè§„æ ¼ï¼‰ã€‚")

        st.markdown("### 2) åŠŸæ•ˆä¸»è½´è¦â€œæŠ€æœ¯â€è¿˜æ˜¯â€œä½“éªŒâ€ï¼Ÿ")
        if np.isfinite(tech_cover):
            if tech_cover >= 0.6:
                st.warning(f"å¸‚åœºå½“å‰åæŠ€æœ¯å™äº‹ï¼ˆæŠ€æœ¯æ ‡ç­¾è¦†ç›– {tech_cover:.1%}ï¼Œtech-heavy {tech_heavy:.1%}ï¼‰ã€‚ä½ è¦ä¹ˆå·æ›´ç¡¬æŠ€æœ¯/è¯æ®ï¼Œè¦ä¹ˆåå‘åšâ€œæ›´å¥½æ‡‚çš„ä½“éªŒè·¯çº¿â€ã€‚")
            else:
                st.success(f"å¸‚åœºæŠ€æœ¯å™äº‹ä¸ç®—å‹å€’æ€§ï¼ˆæŠ€æœ¯è¦†ç›– {tech_cover:.1%}ï¼‰ã€‚æ›´é€‚åˆç”¨â€œæ¸©å’Œã€é•¿æœŸã€ä½“éªŒå¯æ„Ÿâ€åˆ‡å…¥ã€‚")
        else:
            st.info("ç¼ºå°‘æŠ€æœ¯æ ‡ç­¾ä¿¡å·ï¼ˆå¯æ‰©å±• TECH_KW è¯åº“æˆ–è¡¥å……å­—æ®µï¼‰ã€‚")

        st.markdown("### 3) æ˜¯å¦éœ€è¦åŒ»ç–—/ä¸“å®¶èƒŒä¹¦ï¼Ÿ")
        if np.isfinite(med_share):
            if med_share >= 0.5:
                st.warning(f"å»ºè®®ï¼š**éœ€è¦èƒŒä¹¦**ï¼ˆåŒ»ç–—/åŠŸèƒ½å“ç‰Œå æ¯” {med_share:.1%}ï¼‰ã€‚é«˜ä»·ä½æ›´å¯èƒ½ç»‘å®šä¸“ä¸šä¿¡ä»»ã€‚")
            else:
                st.success(f"å»ºè®®ï¼š**ä¸ä¸€å®šéœ€è¦å¼ºèƒŒä¹¦**ï¼ˆåŒ»ç–—/åŠŸèƒ½å“ç‰Œå æ¯” {med_share:.1%}ï¼‰ã€‚æ¶ˆè´¹å“ç‰Œä»æœ‰æœºä¼šé ä½“éªŒ/åŒ…è£…ä¸“ä¸šæ„Ÿè¿›å…¥ã€‚")
        else:
            st.info("ç¼ºå°‘å“ç‰Œå­—æ®µï¼Œæ— æ³•åˆ¤æ–­èƒŒä¹¦æ ¼å±€ã€‚")

        st.markdown("### 4) åˆç†ç›®æ ‡å®šä»· & æ˜¯å¦ä¸€æ­¥åˆ°ä½ï¼Ÿ")
        if np.isfinite(price_median):
            st.write(f"å¸‚åœºä»·æ ¼ä¸­ä½æ•°ï¼ˆæœ‰æ•ˆä»·æ ¼ï¼‰ï¼š**${price_median:.2f}**")
            st.write("å‚è€ƒé”šç‚¹ï¼š")
            if price_median >= 15:
                st.info("å¸‚åœºèƒ½æ¥å—ä¸­é«˜ä»·ã€‚è‹¥ä½ è¦ä¸Šé«˜ä»·ï¼Œå»ºè®®åŒæ­¥å¼ºåŒ–ï¼šæŠ€æœ¯è¯æ®/ä¸“ä¸šèƒŒä¹¦/åŒ…è£…ä¸“ä¸šæ„Ÿã€‚")
            else:
                st.info("å¸‚åœºåä¸­ä½ä»·ã€‚è‹¥ä½ æƒ³æ‹‰é«˜å®¢å•ï¼Œéœ€è¦â€œæ›´å¼ºçš„ç†ç”±â€ï¼ˆä¸´åºŠ/ç¨€ç¼ºæŠ€æœ¯/æ›´å¥½ä½“éªŒï¼‰ã€‚")
        else:
            st.warning("ä»·æ ¼ä¸å¯ç”¨ï¼šè¯·å…ˆä¿®å¤ä»·æ ¼åˆ—æ˜ å°„ã€‚")

        st.markdown("### 5) åŒ…è£…/ç»„åˆè£…æ˜¯å¦æœ‰é£é™©ï¼Ÿï¼ˆFBA proxyï¼‰")
        fba_risk_rate = float(data["FBA_Risk_Flag"].mean()) if len(data) else np.nan
        if np.isfinite(fba_risk_rate):
            st.write(f"Pack>=3 çš„ SKU å æ¯”ï¼š**{fba_risk_rate:.1%}**ï¼ˆè¶Šé«˜è¶Šéœ€è¦æ³¨æ„ FBA æˆæœ¬/ä½“ç§¯ä¸´ç•Œç‚¹ï¼‰")
        else:
            st.write("æ— æ³•è®¡ç®— FBA é£é™© proxyã€‚")

        st.markdown("### 6) æ¸ é“/å¯è§åº¦æ¨¡å‹ï¼ˆproxyï¼‰")
        st.write(channel_txt)

        st.markdown("### 7) å¸‚åœºæˆç†Ÿåº¦ä¸è¿›å…¥éš¾åº¦")
        st.metric("å¸‚åœºæˆç†Ÿåº¦è¯„åˆ†ï¼ˆ0-100ï¼‰", f"{market_maturity_score}/100")
        st.write(f"ç»“è®ºï¼š**{maturity_txt}**")
        st.caption("è¯„åˆ†é€»è¾‘ï¼šä»·æ ¼æ”¶æ•› + æŠ€æœ¯é›†ä¸­ + SKUæ ‡å‡†åŒ–ï¼ˆå¯æŒ‰ç±»ç›®è°ƒæ•´é˜ˆå€¼ï¼‰")

        st.markdown("### 8) Top SKUï¼ˆç”¨äºä½ å¿«é€Ÿå®šä½ç«å“ç­–ç•¥ï¼‰")
        sort_key = None
        if data["clean_sales"].notna().any():
            sort_key = "clean_sales"
        elif data["clean_reviews"].notna().any():
            sort_key = "clean_reviews"
        elif data["clean_revenue"].notna().any():
            sort_key = "clean_revenue"

        if sort_key:
            top = data.sort_values(sort_key, ascending=False).head(20).copy()
            top["_short_title"] = top["Title_Str"].astype(str).str[:80] + "..."
            show_cols = ["_short_title", "clean_price", "Unit_Price_per_item", "Pack_Count", "Origin", "Tech_Main", "Eff_Main", "Selling_Point_Count"]
            if sort_key in top.columns:
                show_cols.insert(1, sort_key)
            st.dataframe(top[show_cols], use_container_width=True, height=420)
        else:
            st.info("ç¼ºå°‘é”€é‡/è¯„è®º/é”€å”®é¢ç­‰æ’åºå­—æ®µï¼Œæ— æ³•è¾“å‡º Top SKUã€‚")

    # åŸå§‹æ•°æ®é¢„è§ˆ
    with st.expander("æŸ¥çœ‹åŸå§‹æ•°æ®ï¼ˆå‰ 50 è¡Œï¼‰", expanded=False):
        st.dataframe(df.head(50), use_container_width=True)


# =============================================================================
# 4. BRAND æ¨¡å—ï¼šå“ç‰Œæ ¼å±€æ¨¡å¼
# =============================================================================
def render_brand_dashboard(df):
    st.info("ğŸ¢ **å“ç‰Œæ ¼å±€æ¨¡å¼**")
    all_cols = df.columns.tolist()
    col_map = {
        "brand": find_col(all_cols, ["brand", "å“ç‰Œ"]),
        "share": find_col(all_cols, ["share", "ä»½é¢"]),
        "rev": find_col(all_cols, ["revenue", "é”€å”®é¢", "gmv", "amount"]),
        "price": find_col(all_cols, ["price", "ä»·æ ¼", "å‡ä»·"])
    }

    with st.expander("ğŸ› ï¸ å­—æ®µæ˜ å°„è®¾ç½®ï¼ˆå“ç‰Œè¡¨ï¼‰", expanded=False):
        cols = [None] + all_cols
        c1, c2, c3, c4 = st.columns(4)
        col_map["brand"] = c1.selectbox("å“ç‰Œ Brand*", cols, index=cols.index(col_map["brand"]) if col_map["brand"] in cols else 0)
        col_map["share"] = c2.selectbox("ä»½é¢ Share", cols, index=cols.index(col_map["share"]) if col_map["share"] in cols else 0)
        col_map["rev"] = c3.selectbox("é”€å”®é¢ Revenue", cols, index=cols.index(col_map["rev"]) if col_map["rev"] in cols else 0)
        col_map["price"] = c4.selectbox("å‡ä»· Price", cols, index=cols.index(col_map["price"]) if col_map["price"] in cols else 0)

    if not col_map["brand"]:
        st.error("ç¼ºå°‘å“ç‰Œåˆ—ï¼Œæ— æ³•åˆ†æã€‚")
        return

    data = df.copy()

    if col_map["share"]:
        data["clean_share"] = data[col_map["share"]].apply(clean_numeric)
    else:
        data["clean_share"] = np.nan

    if col_map["rev"]:
        data["clean_rev"] = data[col_map["rev"]].apply(clean_numeric)
    else:
        data["clean_rev"] = np.nan

    if col_map["price"]:
        data["clean_price"] = data[col_map["price"]].apply(clean_numeric)
    else:
        data["clean_price"] = np.nan

    # é€‰æ‹©ä»·å€¼åˆ—ï¼šä¼˜å…ˆé”€å”®é¢ï¼Œå…¶æ¬¡ä»½é¢
    val_col = None
    if data["clean_rev"].notna().any():
        val_col = "clean_rev"
    elif data["clean_share"].notna().any():
        val_col = "clean_share"

    if not val_col:
        st.error("ç¼ºå°‘é”€å”®é¢æˆ–ä»½é¢æ•°æ®ï¼ˆä¸”è§£æå¤±è´¥ï¼‰ã€‚è¯·æ£€æŸ¥æ˜ å°„æˆ–æ•°æ®æ ¼å¼ã€‚")
        return

    data = data.sort_values(val_col, ascending=False)

    c1, c2 = st.columns(2)
    with c1:
        st.subheader("å“ç‰Œå„æ–­åº¦")
        top5 = float(data.head(5)[val_col].sum(skipna=True))
        total = float(data[val_col].sum(skipna=True))
        cr5 = top5 / total if total > 0 else 0
        st.metric("CR5 (Top5 å æ¯”)", f"{cr5:.1%}")

        fig = px.pie(data.head(10), values=val_col, names=col_map["brand"], title="Top10 å“ç‰Œå æ¯”", hole=0.35)
        st.plotly_chart(fig, use_container_width=True)

    with c2:
        st.subheader("å“ç‰Œä»·æ ¼å¸¦")
        if data["clean_price"].notna().any():
            fig = px.bar(data.head(15), x=col_map["brand"], y="clean_price", title="å¤´éƒ¨å“ç‰Œå‡ä»·å¯¹æ¯”")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("æœªæä¾›ä»·æ ¼åˆ—æˆ–ä»·æ ¼è§£æå¤±è´¥ã€‚")

    with st.expander("æŸ¥çœ‹åŸå§‹æ•°æ®ï¼ˆå‰ 50 è¡Œï¼‰", expanded=False):
        st.dataframe(df.head(50), use_container_width=True)


# =============================================================================
# 5. SELLER æ¨¡å—ï¼šæ¸ é“å–å®¶æ¨¡å¼ï¼ˆå«å›½å®¶ï¼‰â€”â€”ä¿®å¤é¥¼å›¾ bug
# =============================================================================
def render_seller_dashboard(df):
    st.info("ğŸª **æ¸ é“å–å®¶æ¨¡å¼**")
    all_cols = df.columns.tolist()
    col_map = {
        "seller": find_col(all_cols, ["seller", "å–å®¶"]),
        "sales": find_col(all_cols, ["sales", "é”€é‡", "units", "orders"]),
        "country": find_col(all_cols, ["country", "region", "å›½å®¶", "å±åœ°", "location", "origin"]),
    }

    with st.expander("ğŸ› ï¸ å­—æ®µæ˜ å°„è®¾ç½®ï¼ˆå–å®¶è¡¨ï¼‰", expanded=False):
        cols = [None] + all_cols
        c1, c2, c3 = st.columns(3)
        col_map["seller"] = c1.selectbox("å–å®¶ Seller*", cols, index=cols.index(col_map["seller"]) if col_map["seller"] in cols else 0)
        col_map["sales"] = c2.selectbox("é”€é‡ Sales", cols, index=cols.index(col_map["sales"]) if col_map["sales"] in cols else 0)
        col_map["country"] = c3.selectbox("æ‰€å±åœ° Country/Region", cols, index=cols.index(col_map["country"]) if col_map["country"] in cols else 0)

    data = df.copy()

    if col_map["sales"]:
        data["clean_sales"] = data[col_map["sales"]].apply(clean_numeric)
    else:
        data["clean_sales"] = np.nan

    if col_map["country"]:
        data["Origin"] = data[col_map["country"]].apply(clean_country)
    else:
        data["Origin"] = "Unknown"

    c1, c2 = st.columns(2)
    with c1:
        st.subheader("å–å®¶å›½ç±åˆ†å¸ƒ")
        if col_map["country"]:
            cnt = data["Origin"].value_counts(dropna=False).reset_index()
            cnt.columns = ["Origin", "count"]  # âœ… ä¿®å¤ï¼šä¿è¯åˆ—åç¨³å®š
            fig = px.pie(cnt, values="count", names="Origin", title="å–å®¶æ‰€å±åœ°å æ¯”ï¼ˆæŒ‰åº—é“ºæ•°ï¼‰", hole=0.35)
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("æœªæ‰¾åˆ°[å–å®¶æ‰€å±åœ°]åˆ—")

    with c2:
        st.subheader("Top å–å®¶æ’è¡Œ")
        if col_map["seller"] and data["clean_sales"].notna().any():
            top = data.dropna(subset=["clean_sales"]).sort_values("clean_sales", ascending=False).head(10)
            fig = px.bar(top, x="clean_sales", y=col_map["seller"], orientation="h", title="Top10 å–å®¶ï¼ˆæŒ‰é”€é‡ï¼‰")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("ç¼ºå°‘å–å®¶åˆ—æˆ–é”€é‡åˆ—/é”€é‡è§£æå¤±è´¥ï¼Œæ— æ³•è¾“å‡º Top å–å®¶ã€‚")

    with st.expander("æŸ¥çœ‹åŸå§‹æ•°æ®ï¼ˆå‰ 50 è¡Œï¼‰", expanded=False):
        st.dataframe(df.head(50), use_container_width=True)


# =============================================================================
# 6. ä¸»ç¨‹åºå…¥å£
# =============================================================================
st.sidebar.header("ğŸ“‚ ä¸Šä¼ æ–‡ä»¶")
uploaded_file = st.sidebar.file_uploader("ä¸Šä¼  Excel/CSV", type=["xlsx", "csv"])

if uploaded_file:
    dfs = {}
    try:
        if uploaded_file.name.lower().endswith(".csv"):
            try:
                df0 = pd.read_csv(uploaded_file, encoding="utf-8")
            except Exception:
                uploaded_file.seek(0)
                df0 = pd.read_csv(uploaded_file, encoding="gbk")
            dfs["Sheet1"] = df0
        else:
            xl = pd.ExcelFile(uploaded_file)
            for sheet in xl.sheet_names:
                dfs[sheet] = pd.read_excel(uploaded_file, sheet_name=sheet)
                dfs[sheet].columns = dfs[sheet].columns.astype(str).str.strip()
    except Exception as e:
        st.error(f"è¯»å–é”™è¯¯: {e}")
        st.stop()

    st.success(f"æˆåŠŸè¯»å– {len(dfs)} ä¸ªå·¥ä½œè¡¨ï¼š{', '.join(list(dfs.keys()))}")

    tabs = st.tabs([f"ğŸ“‘ {name}" for name in dfs.keys()])
    for i, (name, df_active) in enumerate(dfs.items()):
        with tabs[i]:
            mode = detect_sheet_mode(df_active)
            st.caption(f"å·¥ä½œè¡¨: {name} | æ¨¡å¼: {mode}")

            if mode == "PRODUCT":
                render_product_dashboard(df_active)
            elif mode == "BRAND":
                render_brand_dashboard(df_active)
            elif mode == "SELLER":
                render_seller_dashboard(df_active)
            else:
                st.info("GENERICï¼šæœªè¯†åˆ«å‡ºæ˜ç¡®æ¨¡å¼ï¼Œå±•ç¤ºæ•°æ®é¢„è§ˆã€‚")
                st.dataframe(df_active.head(50), use_container_width=True)
else:
    st.info("ğŸ‘ˆ è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶å¼€å§‹åˆ†æ")
