# -*- coding: utf-8 -*-
import re
import io
import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px

# =============================================================================
# 1) é¡µé¢é…ç½®
# =============================================================================
st.set_page_config(page_title="å¸‚åœº&äº§å“å¼€å‘åˆ†æï¼ˆExcel/CSVï¼‰", layout="wide")
st.title("ğŸ§  å¸‚åœºæ•°æ® â†’ äº§å“å¼€å‘æœºä¼šç‚¹åˆ†æï¼ˆExcel/CSV é€šç”¨ç‰ˆï¼‰")
st.markdown("""
**ä½¿ç”¨è¯´æ˜ï¼š**
1) æ”¯æŒä¸Šä¼  **.xlsx / .csv**  
2) Excel ä¼šè®©ä½ é€‰æ‹© Sheet  
3) é€‰æ‹©/ç¡®è®¤å­—æ®µæ˜ å°„åï¼Œç¨‹åºä¼šè‡ªåŠ¨è¾“å‡ºï¼š  
- **è§„æ ¼å‡€å«é‡ã€è£…æ•°ï¼ˆPackï¼‰ã€å•ä½ä»·æ ¼**  
- **æ ‡é¢˜å…³é”®è¯æ ‡ç­¾ï¼ˆåŠŸæ•ˆ/æŠ€æœ¯/äººç¾¤/åœºæ™¯ï¼‰**  
- **ä»·æ ¼ç»“æ„ã€å“ç‰Œé›†ä¸­åº¦ã€æœºä¼šç‚¹ã€é£é™©ç‚¹**  
- **ä¸­æ–‡å¯è§†åŒ–å›¾è¡¨ + å¯å¯¼å‡º Excel å¤š Sheet æŠ¥å‘Š**
""")

# =============================================================================
# 2) æ–‡ä»¶åŠ è½½
# =============================================================================
def load_file(uploaded_file):
    if uploaded_file is None:
        return None, None, "æ²¡æœ‰æ–‡ä»¶"

    file_name = uploaded_file.name.lower()

    if file_name.endswith(".xlsx"):
        try:
            xl = pd.ExcelFile(uploaded_file)
            return "xlsx", xl, None
        except Exception as e:
            return None, None, f"Excel è¯»å–å¤±è´¥: {str(e)}"

    if file_name.endswith(".csv"):
        encodings = ["utf-8", "gbk", "utf-8-sig", "ISO-8859-1"]
        for enc in encodings:
            try:
                uploaded_file.seek(0)
                df = pd.read_csv(uploaded_file, encoding=enc)
                df.columns = df.columns.astype(str).str.strip()
                return "csv", df, None
            except UnicodeDecodeError:
                continue
            except Exception as e:
                return None, None, str(e)
        return None, None, "CSV ç¼–ç è¯†åˆ«å¤±è´¥ï¼Œè¯·è½¬å­˜ä¸º UTF-8 æ ¼å¼ã€‚"

    return None, None, "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä¸Šä¼  .csv æˆ– .xlsx"


def clean_numeric(val):
    """å°½å¯èƒ½æŠŠå€¼å˜æˆ floatï¼›å¤±è´¥è¿”å› NaN"""
    if pd.isna(val):
        return np.nan
    if isinstance(val, (int, float, np.number)):
        return float(val)
    try:
        s = str(val)
        s = s.replace("$", "").replace("Â¥", "").replace(",", "").replace(" ", "").replace("%", "")
        return float(s)
    except:
        return np.nan


# =============================================================================
# 3) æ›´å¼ºåˆ—åè¯†åˆ«ï¼šå…³é”®è¯è¯åº“ + åŠ æƒæ‰“åˆ†
# =============================================================================
FIELD_KEYWORDS = {
    "asin": {
        "include": ["asin", "sku", "parent asin", "child asin", "asinç ", "çˆ¶asin", "å­asin", "å•†å“id", "äº§å“id", "listing id", "item id"],
        "exclude": ["brand", "title", "name"]
    },
    "brand": {
        "include": ["brand", "å“ç‰Œ", "å“ç‰Œå", "manufacturer", "maker", "å‚ç‰Œ", "company"],
        "exclude": ["brand registry", "brand story", "title"]
    },
    "title": {
        "include": ["title", "name", "product name", "å•†å“å", "å•†å“æ ‡é¢˜", "æ ‡é¢˜", "å“å", "listing title", "product title"],
        "exclude": ["brand", "asin", "sku"]
    },
    "price": {
        "include": ["price", "å”®ä»·", "å½“å‰ä»·", "ç°ä»·", "sale price", "our price", "buy box", "buybox", "ä»·æ ¼", "current price"],
        "exclude": ["list price", "msrp", "coupon", "discount", "save", "off", "promo"]
    },
    "rating": {
        "include": ["rating", "stars", "star", "è¯„åˆ†", "æ˜Ÿçº§", "average rating", "avg rating", "rating score"],
        "exclude": ["ratings count", "review", "reviews", "total ratings", "review count"]
    },
    "reviews": {
        "include": ["reviews", "review", "review count", "ratings count", "total ratings", "è¯„è®ºæ•°", "è¯„ä»·æ•°", "è¯„åˆ†æ•°", "review#", "ratings#", "number of reviews"],
        "exclude": ["rating", "stars", "star", "avg rating"]
    },
    "sales": {
        "include": ["sales", "units", "é”€é‡", "é”€å”®é‡", "unit sold", "sold", "orders", "è®¢å•é‡", "units sold"],
        "exclude": ["sales rank", "rank", "bsr"]
    },
    "revenue": {
        "include": ["revenue", "sales revenue", "é”€å”®é¢", "æˆäº¤é¢", "gmv", "é‡‘é¢", "sales $", "gross sales"],
        "exclude": ["profit", "margin", "net"]
    },
    "size": {
        "include": ["size", "net", "net content", "net wt", "net weight", "å‡€å«é‡", "å‡€é‡", "å«é‡", "oz", "ounce", "ml", "g", "gram", "volume"],
        "exclude": ["dimension", "dimensions", "length", "width", "height", "package", "shipping"]
    },
    "pack": {
        "include": ["pack", "pack of", "count", "qty", "quantity", "æ•°é‡", "è£…", "å¥—è£…", "ç»„åˆ", "variant", "variations", "variation", "flavor", "å£å‘³", "è§„æ ¼"],
        "exclude": ["package weight", "package dimensions", "shipping"]
    },
    "weight": {
        "include": ["weight", "é‡é‡", "package weight", "item weight", "shipping weight", "lbs", "lb", "pounds", "kg"],
        "exclude": ["net wt", "net weight", "å‡€é‡", "å‡€å«é‡"]
    },
    "dimensions": {
        "include": ["dimensions", "dimension", "å°ºå¯¸", "package dimensions", "item dimensions", "length", "width", "height", "cm", "inch", "inches"],
        "exclude": ["size", "net", "oz", "ml", "g", "gram"]
    },
    "rank": {
        "include": ["rank", "bsr", "best sellers rank", "æ’å", "æœç´¢æ’å", "organic rank", "ads rank", "position", "ranking"],
        "exclude": ["rating", "reviews"]
    }
}

def _norm(s: str) -> str:
    s = str(s).strip().lower()
    s = re.sub(r"\s+", " ", s)
    return s

def get_col_index(options, field_key, default=0):
    """
    options: df.columns çš„ list
    field_key: FIELD_KEYWORDS ä¸­çš„ keyï¼Œæ¯”å¦‚ 'price'/'reviews'
    è¿”å›æœ€åŒ¹é…åˆ—çš„ index
    """
    rules = FIELD_KEYWORDS.get(field_key)
    if rules is None:
        return default

    best_i, best_score = default, -10**9
    for i, col in enumerate(options):
        c = _norm(col)
        score = 0

        # include å‘½ä¸­åŠ åˆ†ï¼šè¶Šé å‰å…³é”®è¯æƒé‡è¶Šé«˜
        for j, kw in enumerate(rules["include"]):
            kw_n = _norm(kw)
            if kw_n in c:
                score += 10 - min(j, 8)

        # exclude å‘½ä¸­æ‰£åˆ†
        for kw in rules.get("exclude", []):
            if _norm(kw) in c:
                score -= 12

        # æ›´ç¨³ï¼šå¦‚æœåˆ—åéå¸¸çŸ­ä¸”å®Œå…¨åŒ…å«å…³é”®å­—ï¼Œé¢å¤–åŠ åˆ†
        for kw in rules["include"][:6]:
            kw_n = _norm(kw)
            if kw_n in c and len(c) <= max(len(kw_n) + 8, 18):
                score += 2

        if score > best_score:
            best_score = score
            best_i = i

    return best_i

# =============================================================================
# 4) ç‰¹å¾å·¥ç¨‹ï¼šå‡€å«é‡ / Pack / æ ‡ç­¾
# =============================================================================
UNIT_TO_G = {
    "g": 1.0, "gram": 1.0, "grams": 1.0,
    "kg": 1000.0,
    "oz": 28.3495, "ounce": 28.3495, "ounces": 28.3495,
    "ml": 1.0,      # è¿‘ä¼¼ï¼š1mlâ‰ˆ1gï¼ˆå¦‚éœ€æ›´ç²¾ç¡®å¯æŒ‰å“ç±»å¯†åº¦è°ƒæ•´ï¼‰
    "l": 1000.0,
}

def parse_net_content_to_g(text):
    """
    ä»å­—ç¬¦ä¸²æŠ½å–å‡€å«é‡ï¼Œç»Ÿä¸€æˆ g
    ç¤ºä¾‹ï¼š "4 Ounce", "120g", "100 ml", "0.5 kg"
    """
    if pd.isna(text):
        return np.nan
    s = str(text).lower()

    m = re.search(r"(\d+(?:\.\d+)?)\s*(g|gram|grams|kg|oz|ounce|ounces|ml|l)\b", s)
    if not m:
        return np.nan
    val = float(m.group(1))
    unit = m.group(2)
    return val * UNIT_TO_G.get(unit, np.nan)

def parse_pack_count(text):
    """
    æŠ½å– pack æ•°ï¼ˆPack of 3 / 3 Pack / x3ï¼‰
    å¦‚æœæ²¡æœ‰å°±è¿”å› 1
    """
    if pd.isna(text):
        return 1
    s = str(text).lower()

    m = re.search(r"pack\s*of\s*(\d+)", s)
    if m:
        return int(m.group(1))

    m = re.search(r"(\d+)\s*pack\b", s)
    if m:
        return int(m.group(1))

    m = re.search(r"[xÃ—]\s*(\d+)", s)
    if m:
        return int(m.group(1))

    return 1

# ä½ å¯ä»¥åœ¨ä¾§è¾¹æ æ”¹æˆå¯ç¼–è¾‘è¯åº“ï¼Œè¿™é‡Œç»™é»˜è®¤è¯åº“
DEFAULT_TAG_DICT = {
    "åŠŸæ•ˆ": [
        "whitening", "brighten", "sensitivity", "sensitive", "repair", "remineral", "remineralization", "enamel",
        "gum", "fresh", "breath", "cavity", "anti-caries", "plaque", "tartar", "stain"
    ],
    "æŠ€æœ¯": [
        "nano", "hydroxyapatite", "hap", "fluoride-free", "fluoride free", "xylitol",
        "activated charcoal", "charcoal", "probiotic", "biomimetic"
    ],
    "äººç¾¤": [
        "kids", "children", "adult", "seniors", "pregnant", "braces", "orthodontic"
    ],
    "åœºæ™¯": [
        "night", "daily", "travel", "morning", "after meals"
    ]
}

def extract_tags(title, tag_dict=DEFAULT_TAG_DICT):
    """è¿”å› {group: [hits]}"""
    if pd.isna(title):
        return {k: [] for k in tag_dict.keys()}

    t = str(title).lower()
    res = {}
    for group, kws in tag_dict.items():
        hits = []
        for kw in kws:
            if kw.lower() in t:
                hits.append(kw.lower())
        res[group] = hits
    return res

# =============================================================================
# 5) å¸‚åœºç»“æ„ä¸æœºä¼šç‚¹
# =============================================================================
def add_price_bands(df, price_col, unit_price_col):
    # ä»·æ ¼å¸¦ï¼ˆå¯æŒ‰ä½ å“ç±»è°ƒæ•´ï¼‰
    df["ä»·æ ¼å¸¦"] = pd.cut(
        df[price_col],
        bins=[-0.01, 10, 15, 20, 30, 999999],
        labels=["<10", "10-15", "15-20", "20-30", "30+"]
    )
    # å•ä½ä»·æ ¼å¸¦ï¼ˆåˆ†ä½æ•°åˆ†ç®±ï¼Œä¾¿äºè§„æ ¼å·®å¼‚å¤§æ—¶å¯¹æ¯”ï¼‰
    df["å•ä½ä»·æ ¼åˆ†ä½å¸¦"] = pd.qcut(
        df[unit_price_col].replace([np.inf, -np.inf], np.nan),
        q=5,
        duplicates="drop"
    )
    return df

def brand_concentration(df, brand_col, demand_col):
    """
    ç”¨ demand_colï¼ˆå¦‚ reviews æˆ– salesï¼‰ä½œä¸ºéœ€æ±‚ä»£ç†ï¼Œç®— CR3/5/10
    """
    tmp = df[[brand_col, demand_col]].copy()
    tmp = tmp.dropna(subset=[brand_col])
    tmp[demand_col] = tmp[demand_col].fillna(0)

    brand_sum = tmp.groupby(brand_col)[demand_col].sum().sort_values(ascending=False)
    total = brand_sum.sum() if brand_sum.sum() > 0 else 1.0

    def cr(n):
        return float(brand_sum.head(n).sum() / total)

    return {
        "CR3": cr(3),
        "CR5": cr(5),
        "CR10": cr(10),
        "TopBrands": brand_sum.head(20)
    }

def tag_performance(df, tag_col, price_col, rating_col, demand_col):
    """
    ç»Ÿè®¡ï¼šè¦†ç›–ç‡ã€å‡ä»·ã€è¯„åˆ†ã€éœ€æ±‚ä»£ç†å‡å€¼
    """
    res = []
    tags = df[tag_col].dropna().unique()
    for tag in sorted(tags):
        sub = df[df[tag_col] == tag]
        res.append({
            "æ ‡ç­¾": tag,
            "SKUæ•°": len(sub),
            "è¦†ç›–ç‡": len(sub) / max(len(df), 1),
            "å‡ä»·": sub[price_col].mean(),
            "å‡è¯„åˆ†": sub[rating_col].mean(),
            "éœ€æ±‚ä»£ç†å‡å€¼": sub[demand_col].mean(),
            "éœ€æ±‚ä»£ç†æ€»é‡": sub[demand_col].sum(),
        })
    out = pd.DataFrame(res)
    if len(out) == 0:
        return out
    return out.sort_values(["éœ€æ±‚ä»£ç†æ€»é‡", "å‡è¯„åˆ†"], ascending=False)

def find_opportunities(df, price_col, unit_price_col, rating_col, demand_col, tech_tag_col, eff_tag_col):
    """
    ä¸‰ç±»æœºä¼šï¼š
    1) ä½ä¾›ç»™é«˜éœ€æ±‚ï¼šæ ‡ç­¾ç»„åˆå°‘ä½† demand é«˜
    2) ä»·æ ¼ç©ºæ¡£ï¼šunit_price å¯†åº¦ä½åŒºé—´ + é«˜è¯„åˆ†
    3) é£é™©ç‚¹ï¼šè¦†ç›–é«˜ä½†è¯„åˆ†ä½çš„æ ‡ç­¾ï¼ˆé¿å‘ï¼‰
    """
    out = {}

    # 1) æ ‡ç­¾ç»„åˆï¼ˆæŠ€æœ¯+åŠŸæ•ˆï¼‰
    combo = df[[tech_tag_col, eff_tag_col, demand_col, rating_col, price_col, unit_price_col]].copy()
    combo = combo.dropna(subset=[tech_tag_col, eff_tag_col])
    combo["ç»„åˆ"] = combo[tech_tag_col].astype(str) + " + " + combo[eff_tag_col].astype(str)

    gp = combo.groupby("ç»„åˆ").agg(
        SKUæ•°=("ç»„åˆ", "size"),
        éœ€æ±‚ä»£ç†å‡å€¼=(demand_col, "mean"),
        éœ€æ±‚ä»£ç†æ€»é‡=(demand_col, "sum"),
        å‡è¯„åˆ†=(rating_col, "mean"),
        å‡ä»·=(price_col, "mean"),
        å•ä½ä»·æ ¼å‡å€¼=(unit_price_col, "mean")
    ).reset_index()

    if len(gp) > 0:
        # æœºä¼šåˆ†ï¼šéœ€æ±‚é«˜ï¼ˆrank_pcté«˜ï¼‰ä¸”ä¾›ç»™å°‘ï¼ˆcount_pctä½ï¼‰
        gp["æœºä¼šåˆ†"] = gp["éœ€æ±‚ä»£ç†å‡å€¼"].rank(pct=True) * (1 - gp["SKUæ•°"].rank(pct=True))
        out["ä½ä¾›ç»™é«˜éœ€æ±‚"] = gp.sort_values("æœºä¼šåˆ†", ascending=False).head(15)
    else:
        out["ä½ä¾›ç»™é«˜éœ€æ±‚"] = pd.DataFrame()

    # 2) å•ä½ä»·æ ¼ç©ºæ¡£
    valid = df[[unit_price_col, rating_col, demand_col]].replace([np.inf, -np.inf], np.nan).dropna()
    if len(valid) > 30:
        valid = valid.copy()
        valid["å•ä½ä»·æ ¼æ¡¶"] = pd.qcut(valid[unit_price_col], q=10, duplicates="drop")
        bins = valid.groupby("å•ä½ä»·æ ¼æ¡¶").agg(
            æ¡¶å†…SKUæ•°=(unit_price_col, "size"),
            æ¡¶å†…å‡è¯„åˆ†=(rating_col, "mean"),
            æ¡¶å†…éœ€æ±‚ä»£ç†å‡å€¼=(demand_col, "mean"),
            å•ä½ä»·æ ¼æœ€å°=(unit_price_col, "min"),
            å•ä½ä»·æ ¼æœ€å¤§=(unit_price_col, "max")
        ).reset_index()

        bins["ç©ºæ¡£åˆ†"] = (1 - bins["æ¡¶å†…SKUæ•°"].rank(pct=True)) * bins["æ¡¶å†…å‡è¯„åˆ†"].rank(pct=True)
        out["ä»·æ ¼ç©ºæ¡£"] = bins.sort_values("ç©ºæ¡£åˆ†", ascending=False).head(10)
    else:
        out["ä»·æ ¼ç©ºæ¡£"] = pd.DataFrame()

    # 3) é£é™©æ ‡ç­¾ï¼šè¦†ç›–é«˜ä½†è¯„åˆ†ä½ï¼ˆç”¨åŠŸæ•ˆæ ‡ç­¾ä¸¾ä¾‹ï¼‰
    risk = df[[eff_tag_col, rating_col, demand_col]].dropna(subset=[eff_tag_col])
    rg = risk.groupby(eff_tag_col).agg(
        SKUæ•°=(eff_tag_col, "size"),
        å‡è¯„åˆ†=(rating_col, "mean"),
        éœ€æ±‚ä»£ç†æ€»é‡=(demand_col, "sum")
    ).reset_index()

    if len(rg) > 0:
        rg["é£é™©åˆ†"] = rg["SKUæ•°"].rank(pct=True) * (1 - rg["å‡è¯„åˆ†"].rank(pct=True))
        out["é£é™©ç‚¹"] = rg.sort_values("é£é™©åˆ†", ascending=False).head(15)
    else:
        out["é£é™©ç‚¹"] = pd.DataFrame()

    return out

def to_excel_bytes(sheets: dict):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        for name, sdf in sheets.items():
            if sdf is None:
                continue
            if isinstance(sdf, pd.Series):
                sdf = sdf.reset_index()
            sdf.to_excel(writer, sheet_name=name[:31], index=False)
    output.seek(0)
    return output

# =============================================================================
# 6) ä¾§è¾¹æ ï¼šæ¨¡å¼é€‰æ‹© + ä¸Šä¼ 
# =============================================================================
MODULES = {
    "dev": "ğŸ§© äº§å“å¼€å‘åˆ†æï¼ˆæ¨èï¼‰",
    "product_simple": "ğŸ“¦ åŸºç¡€äº§å“å›¾è¡¨ï¼ˆæ—§ç‰ˆï¼‰",
    "brand_simple": "ğŸ¢ åŸºç¡€å“ç‰Œå æ¯”ï¼ˆæ—§ç‰ˆï¼‰",
}

st.sidebar.header("1) é€‰æ‹©åˆ†ææ¨¡å¼")
analysis_mode = st.sidebar.radio("ä½ æƒ³åˆ†æä»€ä¹ˆï¼Ÿ", list(MODULES.values()), index=0)

st.sidebar.header("2) ä¸Šä¼ æ–‡ä»¶")
uploaded_file = st.sidebar.file_uploader("ä¸Šä¼ æ•°æ®æ–‡ä»¶ (.xlsx / .csv)", type=["xlsx", "csv"])

# =============================================================================
# 7) ä¸»æµç¨‹
# =============================================================================
if not uploaded_file:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ ä¸Šä¼ æ–‡ä»¶")
    st.stop()

file_type, data_obj, error = load_file(uploaded_file)
if error:
    st.error(error)
    st.stop()

# Excel é€‰ Sheet
if file_type == "xlsx":
    sheet_names = data_obj.sheet_names
    st.info(f"æ£€æµ‹åˆ° Excel æ–‡ä»¶ï¼ŒåŒ…å«å·¥ä½œè¡¨: {sheet_names}")
    selected_sheet = st.selectbox("è¯·é€‰æ‹©è¦åˆ†æçš„ Sheet:", sheet_names, index=0)
    df = pd.read_excel(uploaded_file, sheet_name=selected_sheet)
    df.columns = df.columns.astype(str).str.strip()
else:
    df = data_obj

st.subheader("æ•°æ®é¢„è§ˆ")
st.dataframe(df.head(5), use_container_width=True)

all_cols = df.columns.tolist()

# =============================================================================
# A) äº§å“å¼€å‘åˆ†æï¼ˆæ–°ï¼‰
# =============================================================================
if analysis_mode == MODULES["dev"]:
    st.divider()
    st.subheader("ğŸ§© äº§å“å¼€å‘åˆ†æï¼šå­—æ®µæ˜ å°„ï¼ˆè¯·ç¡®è®¤è¯†åˆ«æ˜¯å¦æ­£ç¡®ï¼‰")

    with st.expander("âš™ï¸ è®¾ç½®æ•°æ®åˆ—æ˜ å°„ï¼ˆæ ‡å‡†å­—æ®µï¼‰", expanded=True):
        c1, c2, c3, c4 = st.columns(4)
        col_asin = c1.selectbox(
            "ASIN / SKUï¼ˆå¯é€‰ï¼‰",
            ["(None)"] + all_cols,
            index=get_col_index(["(None)"] + all_cols, "asin")
        )
        col_brand = c2.selectbox(
            "å“ç‰Œï¼ˆBrandï¼‰",
            all_cols,
            index=get_col_index(all_cols, "brand")
        )
        col_title = c3.selectbox(
            "å•†å“æ ‡é¢˜ï¼ˆTitleï¼‰",
            all_cols,
            index=get_col_index(all_cols, "title")
        )
        col_price = c4.selectbox(
            "ä»·æ ¼ï¼ˆPriceï¼‰",
            all_cols,
            index=get_col_index(all_cols, "price")
        )

        c5, c6, c7, c8 = st.columns(4)
        col_rating = c5.selectbox(
            "è¯„åˆ†ï¼ˆRatingï¼Œå¯é€‰ï¼‰",
            ["(None)"] + all_cols,
            index=get_col_index(["(None)"] + all_cols, "rating")
        )
        col_reviews = c6.selectbox(
            "è¯„è®ºæ•°/è¯„ä»·æ•°ï¼ˆReviewsï¼Œå¼ºçƒˆå»ºè®®ä½œä¸ºéœ€æ±‚ä»£ç†ï¼‰",
            ["(None)"] + all_cols,
            index=get_col_index(["(None)"] + all_cols, "reviews")
        )
        col_size = c7.selectbox(
            "å‡€å«é‡/è§„æ ¼ï¼ˆSizeï¼Œå¯é€‰ï¼‰",
            ["(None)"] + all_cols,
            index=get_col_index(["(None)"] + all_cols, "size")
        )
        col_pack = c8.selectbox(
            "è£…æ•°/å˜ä½“ï¼ˆPack/Variantï¼Œå¯é€‰ï¼‰",
            ["(None)"] + all_cols,
            index=get_col_index(["(None)"] + all_cols, "pack")
        )

        c9, c10 = st.columns(2)
        col_weight = c9.selectbox(
            "é‡é‡ï¼ˆWeightï¼Œå¯é€‰ï¼Œç”¨äºç‰©æµ/FBAåˆ¤æ–­ï¼‰",
            ["(None)"] + all_cols,
            index=get_col_index(["(None)"] + all_cols, "weight")
        )
        col_dim = c10.selectbox(
            "å°ºå¯¸ï¼ˆDimensionsï¼Œå¯é€‰ï¼Œç”¨äºç‰©æµ/FBAåˆ¤æ–­ï¼‰",
            ["(None)"] + all_cols,
            index=get_col_index(["(None)"] + all_cols, "dimensions")
        )

    # ------------------------
    # æ•°æ®æ¸…æ´— & ç‰¹å¾å·¥ç¨‹
    # ------------------------
    data = df.copy()
    data["_å“ç‰Œ"] = data[col_brand].astype(str).str.strip()
    data["_æ ‡é¢˜"] = data[col_title].astype(str)

    data["_ä»·æ ¼"] = data[col_price].apply(clean_numeric)

    # è¯„åˆ†
    if col_rating != "(None)":
        data["_è¯„åˆ†"] = data[col_rating].apply(clean_numeric)
    else:
        data["_è¯„åˆ†"] = np.nan

    # éœ€æ±‚ä»£ç†ï¼šä¼˜å…ˆ reviews
    if col_reviews != "(None)":
        data["_éœ€æ±‚ä»£ç†"] = data[col_reviews].apply(clean_numeric).fillna(0)
    else:
        # æ²¡æœ‰ reviews æ—¶ï¼Œä¸ºä¿è¯ç¨‹åºå¯è¿è¡Œï¼Œç»™ä¸€ä¸ªå¼±æ›¿ä»£ï¼ˆä¸å»ºè®®ä¾èµ–ï¼‰
        data["_éœ€æ±‚ä»£ç†"] = (1 / (data["_ä»·æ ¼"].replace(0, np.nan))).fillna(0)

    # å‡€å«é‡ & è£…æ•°
    if col_size != "(None)":
        data["_å‡€å«é‡_g"] = data[col_size].apply(parse_net_content_to_g)
    else:
        data["_å‡€å«é‡_g"] = np.nan

    if col_pack != "(None)":
        data["_è£…æ•°"] = data[col_pack].apply(parse_pack_count)
    else:
        data["_è£…æ•°"] = 1

    # å•ä½ä»·æ ¼ï¼šæœ‰å‡€å«é‡ä¼˜å…ˆï¼Œå¦åˆ™ç”¨å•ä»¶ä»·
    data["_å•ä½ä»·æ ¼"] = np.where(
        data["_å‡€å«é‡_g"].notna() & (data["_å‡€å«é‡_g"] > 0) & data["_è£…æ•°"].notna() & (data["_è£…æ•°"] > 0),
        data["_ä»·æ ¼"] / (data["_å‡€å«é‡_g"] * data["_è£…æ•°"]),
        data["_ä»·æ ¼"] / data["_è£…æ•°"].replace(0, np.nan)
    )

    # æ ‡ç­¾æŠ½å–ï¼šæ¯ç»„å–â€œç¬¬ä¸€ä¸ªå‘½ä¸­æ ‡ç­¾â€ï¼ˆä½ ä¹Ÿå¯ä»¥æ”¹æˆå¤šæ ‡ç­¾ï¼‰
    tags = data["_æ ‡é¢˜"].apply(lambda x: extract_tags(x, DEFAULT_TAG_DICT))
    data["_åŠŸæ•ˆæ ‡ç­¾"] = tags.apply(lambda d: d["åŠŸæ•ˆ"][0] if len(d["åŠŸæ•ˆ"]) else np.nan)
    data["_æŠ€æœ¯æ ‡ç­¾"] = tags.apply(lambda d: d["æŠ€æœ¯"][0] if len(d["æŠ€æœ¯"]) else np.nan)
    data["_äººç¾¤æ ‡ç­¾"] = tags.apply(lambda d: d["äººç¾¤"][0] if len(d["äººç¾¤"]) else np.nan)
    data["_åœºæ™¯æ ‡ç­¾"] = tags.apply(lambda d: d["åœºæ™¯"][0] if len(d["åœºæ™¯"]) else np.nan)

    # ä»·æ ¼å¸¦
    data = add_price_bands(data, "_ä»·æ ¼", "_å•ä½ä»·æ ¼")

    # ------------------------
    # æ ¸å¿ƒæŒ‡æ ‡å¡ç‰‡
    # ------------------------
    st.divider()
    st.subheader("ğŸ“Œ æ ¸å¿ƒæŒ‡æ ‡æ¦‚è§ˆï¼ˆäº§å“å¼€å‘è§†è§’ï¼‰")
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("SKU æ•°", f"{len(data):,}")
    m2.metric("å‡ä»·", f"${np.nanmean(data['_ä»·æ ¼']):.2f}" if np.isfinite(np.nanmean(data["_ä»·æ ¼"])) else "N/A")
    m3.metric("å‡è¯„åˆ†", f"{np.nanmean(data['_è¯„åˆ†']):.2f}" if np.isfinite(np.nanmean(data["_è¯„åˆ†"])) else "N/A")
    m4.metric("éœ€æ±‚ä»£ç†æ€»é‡ï¼ˆReviews/Salesç­‰ï¼‰", f"{data['_éœ€æ±‚ä»£ç†'].sum():,.0f}")

    # =============================================================================
    # å¯è§†åŒ–å›¾è¡¨ï¼ˆä¸­æ–‡ï¼‰
    # =============================================================================
    st.divider()
    st.subheader("ğŸ“Š å¸‚åœºç»“æ„å›¾è¡¨ï¼ˆæ›´è´´è¿‘äº§å“å¼€å‘å†³ç­–ï¼‰")

    cA, cB = st.columns(2)
    with cA:
        st.markdown("##### ä»·æ ¼åˆ†å¸ƒï¼ˆSKU æ•°ï¼‰")
        fig = px.histogram(data.dropna(subset=["_ä»·æ ¼"]), x="_ä»·æ ¼", nbins=25, title="ä»·æ ¼åˆ†å¸ƒï¼ˆSKU æ•°ï¼‰")
        st.plotly_chart(fig, use_container_width=True)

    with cB:
        st.markdown("##### å•ä½ä»·æ ¼åˆ†å¸ƒï¼ˆç”¨äºè§„æ ¼å·®å¼‚å¤§æ—¶ï¼‰")
        tmp = data.replace([np.inf, -np.inf], np.nan).dropna(subset=["_å•ä½ä»·æ ¼"])
        fig = px.histogram(tmp, x="_å•ä½ä»·æ ¼", nbins=25, title="å•ä½ä»·æ ¼åˆ†å¸ƒï¼ˆè¿‘ä¼¼ï¼š$/g æˆ– $/mlï¼‰")
        st.plotly_chart(fig, use_container_width=True)

    # ä»·æ ¼å¸¦æŒ‰â€œéœ€æ±‚ä»£ç†â€åŠ æƒ
    st.markdown("##### ä»·æ ¼å¸¦ç»“æ„ï¼ˆæŒ‰éœ€æ±‚ä»£ç†åŠ æƒï¼Œæ›´æ¥è¿‘çœŸå®å¸‚åœºï¼‰")
    band = data.groupby("ä»·æ ¼å¸¦", dropna=False)["_éœ€æ±‚ä»£ç†"].sum().reset_index()
    band.columns = ["ä»·æ ¼å¸¦", "éœ€æ±‚ä»£ç†æ€»é‡"]
    fig = px.bar(band, x="ä»·æ ¼å¸¦", y="éœ€æ±‚ä»£ç†æ€»é‡", title="ä»·æ ¼å¸¦éœ€æ±‚åˆ†å¸ƒï¼ˆéœ€æ±‚ä»£ç†åŠ æƒï¼‰")
    st.plotly_chart(fig, use_container_width=True)

    # ä»·æ ¼ vs è¯„åˆ†ï¼ˆç‚¹å¤§å°=éœ€æ±‚ä»£ç†ï¼‰
    st.markdown("##### ä»·æ ¼ vs è¯„åˆ†ï¼ˆåˆ¤æ–­æº¢ä»·æ˜¯å¦æˆç«‹ï¼›ç‚¹è¶Šå¤§=éœ€æ±‚ä»£ç†è¶Šå¤§ï¼‰")
    scatter_df = data.replace([np.inf, -np.inf], np.nan).dropna(subset=["_ä»·æ ¼"])
    if scatter_df["_è¯„åˆ†"].notna().sum() > 0:
        fig = px.scatter(
            scatter_df,
            x="_ä»·æ ¼",
            y="_è¯„åˆ†",
            size="_éœ€æ±‚ä»£ç†",
            hover_data=["_å“ç‰Œ", "_æ ‡é¢˜", "_å•ä½ä»·æ ¼", "_è£…æ•°", "_åŠŸæ•ˆæ ‡ç­¾", "_æŠ€æœ¯æ ‡ç­¾"],
            title="ä»·æ ¼ vs è¯„åˆ†ï¼ˆæ°”æ³¡å›¾ï¼‰"
        )
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("å½“å‰æœªæä¾›è¯„åˆ†åˆ—ï¼ˆRatingï¼‰ï¼Œå› æ­¤æ— æ³•ç»˜åˆ¶â€œä»·æ ¼ vs è¯„åˆ†â€å›¾ã€‚")

    # Pack è£…æ•°å½±å“ï¼šå•ä½ä»·æ ¼ç®±çº¿å›¾ + éœ€æ±‚æŸ±çŠ¶å›¾
    st.markdown("##### è£…æ•°ï¼ˆPackï¼‰å¯¹å•ä½ä»·æ ¼ä¸éœ€æ±‚çš„å½±å“ï¼ˆå†³å®šè¦ä¸è¦åšå¤šæ”¯è£…ï¼‰")
    pack_tmp = data.replace([np.inf, -np.inf], np.nan).dropna(subset=["_è£…æ•°", "_å•ä½ä»·æ ¼"])
    fig = px.box(pack_tmp, x="_è£…æ•°", y="_å•ä½ä»·æ ¼", points="all", title="ä¸åŒè£…æ•°çš„å•ä½ä»·æ ¼åˆ†å¸ƒï¼ˆç®±çº¿å›¾ï¼‰")
    st.plotly_chart(fig, use_container_width=True)

    pack_demand = data.groupby("_è£…æ•°")["_éœ€æ±‚ä»£ç†"].sum().reset_index()
    fig = px.bar(pack_demand, x="_è£…æ•°", y="_éœ€æ±‚ä»£ç†", title="ä¸åŒè£…æ•°çš„éœ€æ±‚ä»£ç†æ€»é‡")
    st.plotly_chart(fig, use_container_width=True)

    # æ ‡ç­¾çƒ­åº¦ï¼ˆæŠ€æœ¯/åŠŸæ•ˆï¼‰Top15ï¼šéœ€æ±‚ä»£ç†æ€»é‡
    st.markdown("##### æ ‡ç­¾çƒ­åº¦ï¼ˆç”¨äºå†³å®šäº§å“ä¸»è½´ï¼‰")
    col1, col2 = st.columns(2)

    with col1:
        tech_hot = data.groupby("_æŠ€æœ¯æ ‡ç­¾")["_éœ€æ±‚ä»£ç†"].sum().reset_index()
        tech_hot = tech_hot.dropna().sort_values("_éœ€æ±‚ä»£ç†", ascending=False).head(15)
        tech_hot.columns = ["æŠ€æœ¯æ ‡ç­¾", "éœ€æ±‚ä»£ç†æ€»é‡"]
        fig = px.bar(tech_hot, x="éœ€æ±‚ä»£ç†æ€»é‡", y="æŠ€æœ¯æ ‡ç­¾", orientation="h", title="æŠ€æœ¯æ ‡ç­¾çƒ­åº¦ Top15")
        st.plotly_chart(fig, use_container_width=True)

    with col2:
        eff_hot = data.groupby("_åŠŸæ•ˆæ ‡ç­¾")["_éœ€æ±‚ä»£ç†"].sum().reset_index()
        eff_hot = eff_hot.dropna().sort_values("_éœ€æ±‚ä»£ç†", ascending=False).head(15)
        eff_hot.columns = ["åŠŸæ•ˆæ ‡ç­¾", "éœ€æ±‚ä»£ç†æ€»é‡"]
        fig = px.bar(eff_hot, x="éœ€æ±‚ä»£ç†æ€»é‡", y="åŠŸæ•ˆæ ‡ç­¾", orientation="h", title="åŠŸæ•ˆæ ‡ç­¾çƒ­åº¦ Top15")
        st.plotly_chart(fig, use_container_width=True)

    # =============================================================================
    # å“ç‰Œé›†ä¸­åº¦
    # =============================================================================
    st.divider()
    st.subheader("ğŸ¢ å“ç‰Œæ ¼å±€ï¼ˆé›†ä¸­åº¦ï¼‰")
    conc = brand_concentration(data, "_å“ç‰Œ", "_éœ€æ±‚ä»£ç†")
    c1, c2, c3 = st.columns(3)
    c1.metric("CR3ï¼ˆå‰3å“ç‰Œä»½é¢ï¼‰", f"{conc['CR3']*100:.1f}%")
    c2.metric("CR5ï¼ˆå‰5å“ç‰Œä»½é¢ï¼‰", f"{conc['CR5']*100:.1f}%")
    c3.metric("CR10ï¼ˆå‰10å“ç‰Œä»½é¢ï¼‰", f"{conc['CR10']*100:.1f}%")

    top_brands = conc["TopBrands"].reset_index()
    top_brands.columns = ["å“ç‰Œ", "éœ€æ±‚ä»£ç†æ€»é‡"]
    fig = px.bar(top_brands.head(15), x="éœ€æ±‚ä»£ç†æ€»é‡", y="å“ç‰Œ", orientation="h", title="Top å“ç‰Œï¼ˆæŒ‰éœ€æ±‚ä»£ç†æ€»é‡ï¼‰")
    st.plotly_chart(fig, use_container_width=True)

    # =============================================================================
    # æ ‡ç­¾è¡¨ç°ï¼ˆè¡¨æ ¼ï¼‰
    # =============================================================================
    st.divider()
    st.subheader("ğŸ·ï¸ å–ç‚¹æ ‡ç­¾è¡¨ç°ï¼ˆç”¨äºå®šä¹‰æŠ€æœ¯è·¯çº¿/åŠŸæ•ˆä¸»è½´ï¼‰")
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("##### æŠ€æœ¯æ ‡ç­¾è¡¨ç°")
        tech_perf = tag_performance(data, "_æŠ€æœ¯æ ‡ç­¾", "_ä»·æ ¼", "_è¯„åˆ†", "_éœ€æ±‚ä»£ç†")
        st.dataframe(tech_perf, use_container_width=True, height=360)

    with col2:
        st.markdown("##### åŠŸæ•ˆæ ‡ç­¾è¡¨ç°")
        eff_perf = tag_performance(data, "_åŠŸæ•ˆæ ‡ç­¾", "_ä»·æ ¼", "_è¯„åˆ†", "_éœ€æ±‚ä»£ç†")
        st.dataframe(eff_perf, use_container_width=True, height=360)

    # =============================================================================
    # æœºä¼šç‚¹ä¸é£é™©ç‚¹
    # =============================================================================
    st.divider()
    st.subheader("ğŸ¯ æœºä¼šç‚¹ä¸é£é™©ç‚¹ï¼ˆç›´æ¥ç»™äº§å“å¼€å‘ç”¨ï¼‰")

    opp = find_opportunities(
        data,
        price_col="_ä»·æ ¼",
        unit_price_col="_å•ä½ä»·æ ¼",
        rating_col="_è¯„åˆ†",
        demand_col="_éœ€æ±‚ä»£ç†",
        tech_tag_col="_æŠ€æœ¯æ ‡ç­¾",
        eff_tag_col="_åŠŸæ•ˆæ ‡ç­¾"
    )

    c1, c2 = st.columns(2)
    with c1:
        st.markdown("##### æœºä¼š1ï¼šä½ä¾›ç»™é«˜éœ€æ±‚ï¼ˆæŠ€æœ¯ + åŠŸæ•ˆ æ ‡ç­¾ç»„åˆï¼‰")
        st.dataframe(opp["ä½ä¾›ç»™é«˜éœ€æ±‚"], use_container_width=True, height=360)
    with c2:
        st.markdown("##### æœºä¼š2ï¼šå•ä½ä»·æ ¼ç©ºæ¡£ï¼ˆGapï¼‰")
        st.dataframe(opp["ä»·æ ¼ç©ºæ¡£"], use_container_width=True, height=360)

    st.markdown("##### é£é™©ç‚¹ï¼šè¦†ç›–é«˜ä½†è¯„åˆ†åä½çš„åŠŸæ•ˆæ ‡ç­¾ï¼ˆé¿å‘æ¸…å•ï¼‰")
    st.dataframe(opp["é£é™©ç‚¹"], use_container_width=True)

    # =============================================================================
    # æ¸…æ´—åçš„æ˜ç»†ï¼ˆå¯é€‰å±•ç¤ºï¼‰
    # =============================================================================
    with st.expander("ğŸ” æŸ¥çœ‹æ¸…æ´—åçš„æ•°æ®æ˜ç»†ï¼ˆå¯ç”¨äºäºŒæ¬¡åˆ†æï¼‰", expanded=False):
        show_cols = ["_å“ç‰Œ", "_æ ‡é¢˜", "_ä»·æ ¼", "_è¯„åˆ†", "_éœ€æ±‚ä»£ç†", "_å‡€å«é‡_g", "_è£…æ•°", "_å•ä½ä»·æ ¼",
                    "_åŠŸæ•ˆæ ‡ç­¾", "_æŠ€æœ¯æ ‡ç­¾", "_äººç¾¤æ ‡ç­¾", "_åœºæ™¯æ ‡ç­¾", "ä»·æ ¼å¸¦", "å•ä½ä»·æ ¼åˆ†ä½å¸¦"]
        if col_asin != "(None)":
            data["_ASIN/SKU"] = data[col_asin].astype(str)
            show_cols = ["_ASIN/SKU"] + show_cols
        st.dataframe(data[show_cols].head(200), use_container_width=True)

    # =============================================================================
    # å¯¼å‡º Excelï¼ˆå¤š Sheetï¼‰
    # =============================================================================
    st.divider()
    st.subheader("â¬‡ï¸ å¯¼å‡ºæŠ¥å‘Šï¼ˆExcel å¤š Sheetï¼‰")

    export_sheets = {
        "æ¸…æ´—æ•°æ®_cleaned": data.replace([np.inf, -np.inf], np.nan),
        "å“ç‰ŒTop_top_brands": top_brands,
        "æŠ€æœ¯æ ‡ç­¾è¡¨ç°_tech_perf": tech_perf,
        "åŠŸæ•ˆæ ‡ç­¾è¡¨ç°_eff_perf": eff_perf,
        "æœºä¼š_ä½ä¾›ç»™é«˜éœ€æ±‚": opp["ä½ä¾›ç»™é«˜éœ€æ±‚"],
        "æœºä¼š_ä»·æ ¼ç©ºæ¡£": opp["ä»·æ ¼ç©ºæ¡£"],
        "é£é™©ç‚¹_risk": opp["é£é™©ç‚¹"],
        "ä»·æ ¼å¸¦éœ€æ±‚_band": band,
        "è£…æ•°éœ€æ±‚_pack_demand": pack_demand,
    }
    excel_bytes = to_excel_bytes(export_sheets)

    st.download_button(
        label="ğŸ“¥ ä¸‹è½½åˆ†æç»“æœ Excelï¼ˆå«å¤šSheetï¼‰",
        data=excel_bytes,
        file_name="market_product_dev_report_cn.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

# =============================================================================
# B) æ—§ç‰ˆï¼šåŸºç¡€äº§å“å›¾è¡¨
# =============================================================================
elif analysis_mode == MODULES["product_simple"]:
    st.divider()
    st.subheader("ğŸ“¦ åŸºç¡€äº§å“å›¾è¡¨ï¼ˆæ—§ç‰ˆï¼‰")

    with st.expander("âš™ï¸ è®¾ç½®æ•°æ®åˆ—ï¼ˆå¯¹åº”å…³ç³»ï¼‰", expanded=True):
        c1, c2, c3, c4 = st.columns(4)
        col_price = c1.selectbox("ä»·æ ¼åˆ—", all_cols, index=get_col_index(all_cols, "price"))
        col_sales = c2.selectbox("é”€é‡åˆ—ï¼ˆå¯é€‰ï¼‰", ["(None)"] + all_cols, index=get_col_index(["(None)"] + all_cols, "sales"))
        col_rev = c3.selectbox("é”€å”®é¢åˆ—ï¼ˆå¯é€‰ï¼‰", ["(None)"] + all_cols, index=get_col_index(["(None)"] + all_cols, "revenue"))
        col_title = c4.selectbox("å•†å“æ ‡é¢˜/åç§°åˆ—", all_cols, index=get_col_index(all_cols, "title"))

    try:
        df2 = df.copy()
        df2["_ä»·æ ¼"] = df2[col_price].apply(clean_numeric)

        if col_sales != "(None)":
            df2["_é”€é‡"] = df2[col_sales].apply(clean_numeric).fillna(0)
        else:
            df2["_é”€é‡"] = 0

        if col_rev != "(None)":
            df2["_é”€å”®é¢"] = df2[col_rev].apply(clean_numeric).fillna(0)
        else:
            df2["_é”€å”®é¢"] = np.nan

        m1, m2, m3 = st.columns(3)
        m1.metric("æ€»é”€å”®é¢", f"${np.nansum(df2['_é”€å”®é¢']):,.0f}" if col_rev != "(None)" else "N/A")
        m2.metric("æ€»é”€é‡", f"{np.nansum(df2['_é”€é‡']):,.0f}" if col_sales != "(None)" else "N/A")
        m3.metric("å¹³å‡ä»·æ ¼", f"${np.nanmean(df2['_ä»·æ ¼']):.2f}")

        g1, g2 = st.columns(2)
        with g1:
            st.markdown("##### ä»·æ ¼åˆ†å¸ƒ")
            fig = px.histogram(df2.dropna(subset=["_ä»·æ ¼"]), x="_ä»·æ ¼", nbins=20, title="ä»·æ ¼åŒºé—´åˆ†å¸ƒ")
            st.plotly_chart(fig, use_container_width=True)

        with g2:
            if col_sales == "(None)":
                st.info("æœªé€‰æ‹©â€œé”€é‡åˆ—â€ï¼Œæ— æ³•è¾“å‡ºé”€é‡Top10ã€‚")
            else:
                st.markdown("##### é”€é‡ Top 10 å•†å“")
                top_items = df2.sort_values("_é”€é‡", ascending=False).head(10).copy()
                top_items["_çŸ­æ ‡é¢˜"] = top_items[col_title].astype(str).str[:30] + "..."
                fig = px.bar(top_items, x="_é”€é‡", y="_çŸ­æ ‡é¢˜", orientation="h", title="çƒ­é”€å•†å“ï¼ˆTop10ï¼‰")
                st.plotly_chart(fig, use_container_width=True)

    except Exception as e:
        st.error(f"åˆ†æå‡ºé”™ï¼Œè¯·æ£€æŸ¥ä¸Šæ–¹åˆ—åæ˜¯å¦é€‰æ‹©æ­£ç¡®ã€‚\né”™è¯¯ä¿¡æ¯: {e}")

# =============================================================================
# C) æ—§ç‰ˆï¼šåŸºç¡€å“ç‰Œå æ¯”
# =============================================================================
elif analysis_mode == MODULES["brand_simple"]:
    st.divider()
    st.subheader("ğŸ¢ åŸºç¡€å“ç‰Œå æ¯”ï¼ˆæ—§ç‰ˆï¼‰")

    with st.expander("âš™ï¸ è®¾ç½®æ•°æ®åˆ—ï¼ˆå¯¹åº”å…³ç³»ï¼‰", expanded=True):
        c1, c2 = st.columns(2)
        b_name = c1.selectbox("å“ç‰Œåç§°åˆ—", all_cols, index=get_col_index(all_cols, "brand"))
        b_val = c2.selectbox("é”€å”®é¢/å æ¯”åˆ—", all_cols, index=get_col_index(all_cols, "revenue"))

    try:
        df3 = df.copy()
        df3["_å€¼"] = df3[b_val].apply(clean_numeric).fillna(0)

        st.markdown("##### å“ç‰Œå¸‚åœºå æ¯”ï¼ˆTop15ï¼‰")
        df_sorted = df3.sort_values("_å€¼", ascending=False).head(15)
        fig = px.pie(df_sorted, values="_å€¼", names=b_name, title="Top 15 å“ç‰Œå æ¯”", hole=0.4)
        st.plotly_chart(fig, use_container_width=True)

        st.markdown("##### å“ç‰Œæ•°æ®æ˜ç»†")
        st.dataframe(df3, use_container_width=True)

    except Exception as e:
        st.error(f"åˆ†æå‡ºé”™ï¼Œè¯·æ£€æŸ¥ä¸Šæ–¹åˆ—åæ˜¯å¦é€‰æ‹©æ­£ç¡®ã€‚\né”™è¯¯ä¿¡æ¯: {e}")
